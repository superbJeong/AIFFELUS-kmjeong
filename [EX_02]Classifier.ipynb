{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65aab688",
   "metadata": {},
   "source": [
    "# [E_02] Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81bfa6",
   "metadata": {},
   "source": [
    "---\n",
    "# Project 1: 손글씨 분류\n",
    "## (1) 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a0f38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits # 손글씨 데이터를 로드\n",
    "from sklearn.model_selection import train_test_split # train과 test 셋으로 나눠줌\n",
    "from sklearn.metrics import classification_report # 테스트 결과를 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d5027",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c07cc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits() # 손글씨 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41aa9ab",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61c28798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Feature Data 지정하기\n",
    "digit_data = digits.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "digit_label = digits.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7c4e2",
   "metadata": {},
   "source": [
    "## (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e70f0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digit_data, digit_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce7271",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f039742a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state는 동일하게 42로 설정\n",
    "# Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=3000) # 뭔가 max_iter를 지정해주라는 경고가 떠서 검색후 보통 사용하는 값으로 설정\n",
    "#logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ff491",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfc9a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Decision Tree *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92        39\n",
      "           1       0.99      0.92      0.95        75\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.95      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "\n",
      "********* Random Forest *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        39\n",
      "           1       0.97      1.00      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.97      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "\n",
      "********* Support Vector Machine *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        39\n",
      "           1       0.94      1.00      0.97        75\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.94      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "********* SGD Classifier *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        39\n",
      "           1       0.88      1.00      0.94        75\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.94      0.87      0.90       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "\n",
      "********* Logistic Regression *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.99      0.99      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descision Tree\n",
    "y_pred_deci = decision_tree.predict(X_test)\n",
    "print(\"\\n********* Decision Tree *********\\n\")\n",
    "print(classification_report(y_test, y_pred_deci))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rand = random_forest.predict(X_test)\n",
    "print(\"\\n********* Random Forest *********\\n\")\n",
    "print(classification_report(y_test, y_pred_rand))\n",
    "\n",
    "# SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"\\n********* Support Vector Machine *********\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# SGD Classifier\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(\"\\n********* SGD Classifier *********\\n\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_logi = logistic_model.predict(X_test)\n",
    "print(\"\\n********* Logistic Regression *********\\n\")\n",
    "print(classification_report(y_test, y_pred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa6ae4",
   "metadata": {},
   "source": [
    "---\n",
    "# Project 2: 와인 분류\n",
    "## (1) 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75d4ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f007b31",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab35fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f478f9",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe3eab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# Feature Data 지정하기\n",
    "wine_data = wine.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "wine_label = wine.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fafe9",
   "metadata": {},
   "source": [
    "## (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25b53546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fc199",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c08c22c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state는 동일하게 43으로 설정\n",
    "# Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=43)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=43)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logistic_model = LogisticRegression(max_iter=3000): 3000으로 하니 max를 넘어갔다는 경고가 나와 단순히 높여줌\n",
    "logistic_model = LogisticRegression(max_iter=5000)\n",
    "logistic_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76724d92",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e0e2328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Decision Tree *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        14\n",
      "           1       0.92      0.86      0.89        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.93      0.93        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "\n",
      "********* Random Forest *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "********* Support Vector Machine *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.69      0.64      0.67        14\n",
      "           2       0.44      0.50      0.47         8\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.69      0.69      0.69        36\n",
      "weighted avg       0.73      0.72      0.72        36\n",
      "\n",
      "\n",
      "********* SGD Classifier *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.74        14\n",
      "           1       0.67      0.71      0.69        14\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.43      0.55      0.48        36\n",
      "weighted avg       0.50      0.64      0.56        36\n",
      "\n",
      "\n",
      "********* Logistic Regression *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.93      0.93      0.93        14\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Descision Tree\n",
    "y_pred_deci = decision_tree.predict(X_test)\n",
    "print(\"\\n********* Decision Tree *********\\n\")\n",
    "print(classification_report(y_test, y_pred_deci))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rand = random_forest.predict(X_test)\n",
    "print(\"\\n********* Random Forest *********\\n\")\n",
    "print(classification_report(y_test, y_pred_rand))\n",
    "\n",
    "# SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"\\n********* Support Vector Machine *********\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# SGD Classifier\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(\"\\n********* SGD Classifier *********\\n\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_logi = logistic_model.predict(X_test)\n",
    "print(\"\\n********* Logistic Regression *********\\n\")\n",
    "print(classification_report(y_test, y_pred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e66abe",
   "metadata": {},
   "source": [
    "---\n",
    "# Project 3: 유방암 여부 진단\n",
    "## (1) 필요한 모듈 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e39ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c3b90",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a93724ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc84db5",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14123019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Feature Data 지정하기\n",
    "breast_cancer_data = breast_cancer.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "breast_cancer_label = breast_cancer.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c38de14",
   "metadata": {},
   "source": [
    "## (4) train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e7dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bdf43",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aea906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_state는 동일하게 44로 설정\n",
    "# Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=44)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=44)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=3000)\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b33fc",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee185117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Decision Tree *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92        39\n",
      "           1       0.99      0.92      0.95        75\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.95      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "\n",
      "********* Random Forest *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        39\n",
      "           1       0.97      1.00      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.97      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "\n",
      "********* Support Vector Machine *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        39\n",
      "           1       0.94      1.00      0.97        75\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.94      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "********* SGD Classifier *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85        39\n",
      "           1       0.88      1.00      0.94        75\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.94      0.87      0.90       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "\n",
      "********* Logistic Regression *********\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.99      0.99      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descision Tree\n",
    "y_pred_deci = decision_tree.predict(X_test)\n",
    "print(\"\\n********* Decision Tree *********\\n\")\n",
    "print(classification_report(y_test, y_pred_deci))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rand = random_forest.predict(X_test)\n",
    "print(\"\\n********* Random Forest *********\\n\")\n",
    "print(classification_report(y_test, y_pred_rand))\n",
    "\n",
    "# SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"\\n********* Support Vector Machine *********\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# SGD Classifier\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(\"\\n********* SGD Classifier *********\\n\")\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_logi = logistic_model.predict(X_test)\n",
    "print(\"\\n********* Logistic Regression *********\\n\")\n",
    "print(classification_report(y_test, y_pred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a55db4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc29f9",
   "metadata": {},
   "source": [
    "# 결과 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c3f7f",
   "metadata": {},
   "source": [
    "평가문항\t상세기준\n",
    "1. 3가지 데이터셋의 구성이 합리적으로 진행되었는가?  \n",
    "  - feature와 label 선정을 위한 데이터 분석과정이 체계적으로 전개됨  \n",
    "    \n",
    "\n",
    "2. 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?  \n",
    "  - 모델학습 및 테스트가 정상적으로 수행되었음  \n",
    "    \n",
    "\n",
    "3. 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가?  \n",
    "  - 평가지표 선택 및 이유 설명이 타당함  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab68316",
   "metadata": {},
   "source": [
    "#### 1. 손글씨\n",
    "* 숫자를 0에서 9까지 각각을 다 잘 맞춰야 하므로, FN(False Negative)가 작아야 한다고 생각\n",
    "* 그러므로 Recall 값을 비교하는 것이 적절\n",
    "* Recall 비교\n",
    "\\# Descision Tree: 0.94  \n",
    "\\# Random Forest: 0.98  \n",
    "\\# Support Vector Machine: 0.96  \n",
    "\\# SGD Classifier: 0.91  \n",
    "\\# Logistic Regression: 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4fddc",
   "metadata": {},
   "source": [
    "#### 2. 와인\n",
    "* 와인의 종류를 구별하는 문제로, 역시나 FN(False Negative)가 작아야 한다고 생각\n",
    "* 그러므로 Recall 값을 비교하는 것이 적절\n",
    "* Recall 비교\n",
    "\\# Descision Tree: 0.92  \n",
    "\\# Random Forest: 1.0  \n",
    "\\# Support Vector Machine: 0.72  \n",
    "\\# SGD Classifier: 0.64  \n",
    "\\# Logistic Regression: 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6eb6f",
   "metadata": {},
   "source": [
    "#### 3. 유방암\n",
    "* 유방암 여부를 양성/음성 두 가지중 하나로 판별하는 문제이므로,  \n",
    "어느 하나에 집중하기 보다는 양성이면 양성, 음성이면 음성이라고 제대로 판별해야 한다고 생각\n",
    "* 그러므로 Precision과 Recall을 모두 포함하는 f1-score를 활용\n",
    "* f1-score 비교\n",
    "\\# Descision Tree: 0.94  \n",
    "\\# Random Forest: 0.98  \n",
    "\\# Support Vector Machine: 0.96  \n",
    "\\# SGD Classifier: 0.91  \n",
    "\\# Logistic Regression: 0.98  \n",
    "  \n",
    "  \n",
    "* Random Forest와 Logistic Regression이 동일한 값이므로, 추가적인 비교가 필요\n",
    "* 양성인데 음성이라고 판단하는 경우가 더 치명적이므로 실제 양성인 경우(TP + FN)가 중요\n",
    " - Recall 추가 비교해본 결과 두 Classifier가 같은 값을 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b8f9a",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52438579",
   "metadata": {},
   "source": [
    "* sickit-learn을 활용하면 다양한 Classifier를 쉽게 활용할 수 있다!\n",
    "\n",
    "\n",
    "* 테스트 결과를 비교하는 metric으로 accuracy와 precision, recall이 있고,  \n",
    "데이터의 특성에 따라 선택해야하는 비교 기법이 다르다!\n",
    "\n",
    "\n",
    "* 계속해서 여러가지 라이브러리들을 학습하고 활용해보고 있는데,  \n",
    "각각의 장단점이 있을것이므로 이를 잘 파악해서 실제 프로젝트 진행 시 적합한 것으로 선택하는 것이 중요할 듯!\n",
    "  \n",
    "  \n",
    "* 아직 시각화에 대한 숙달이 안되어 활용을 못했지만,  \n",
    "시각화에 대한 필요성을 매번 느끼고 있으며 빠르게 학습해야 할 필요가 있다...!!!\n",
    "\n",
    "\n",
    "* Logistic Regression을 활용하는 과정에서 max_iter 관련 경고가 있었다.  \n",
    "solver를 몇 번 반복할 것인지에 대한 내용인데 이게 수렴이 되면 그 다음으로는 몇 번을 수행하든 변화가 없다.  \n",
    "그저 수행 시간만 길어지는데, 그렇다면 어떻게 이 값을 적절하게 조절할 수 있는 것인가?  \n",
    "역시나 시각화를 하는것이 중요한 것인가? 하는 의문이 든다.  \n",
    "max_iter 관련해서는 조금 더 알아봐야할 필요가 있다!!  \n",
    "\n",
    " -> GridSearchCV를 활용하거나, RandomizedSearchCV 또는 BayesianOptimization를 활용하는 방법이 있다고 한다!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
