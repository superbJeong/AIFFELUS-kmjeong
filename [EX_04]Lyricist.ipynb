{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e78bad",
   "metadata": {},
   "source": [
    "# [EX_04] 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8fe5c",
   "metadata": {},
   "source": [
    "## 1. 데이터 다운로드\n",
    "* Cloud Shell에서 다음 명령어 입력\n",
    " ```\n",
    " $ mkdir -p ~/aiffel/lyricist/models  #폴더를 생성\n",
    " $ ln -s ~/data ~/aiffel/lyricist/data  #폴더 연결\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74766459",
   "metadata": {},
   "source": [
    "## 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2089d85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME') + '/aiffel/lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa14d6",
   "metadata": {},
   "source": [
    "## 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a893c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758aeb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(sentence): \n",
    "    # 입력된 문장을\n",
    "    sentence = sentence.lower().strip() #                     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) #     2. 특수문자 양쪽에 공백을 넣고\n",
    "    sentence = re.sub(r'(\" \")+', \" \", sentence) #             3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "    sentence = re.sub(r\"[^a-zA-Z.!,¿]+\", \" \", sentence) #    4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "    sentence = sentence.strip() #                             5. 다시 양쪽 공백을 지웁니다\n",
    "    sentence = \"<start> \" + sentence + \" <end>\" #             6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "    return sentence\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0 : continue # 문장의 길이가 0인 경우 건너뜀\n",
    "    if sentence[-1] == ':': continue # 문장의 마지막이 ':'으로 끝날 경우 건너뜀 -> 화자가 표기된 의미없는 문장이기 때문\n",
    "        \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessed_sentence.split()) > 15: continue # 단어별로 토큰화 되기 때문에 15단어를 넘어가는 문장을 제외 -> 토큰 사이즈를 제한\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295e651",
   "metadata": {},
   "source": [
    "## 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8437e5d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   49    4 ...    0    0    0]\n",
      " [   2   15 2970 ...    0    0    0]\n",
      " [   2   33    7 ...    3    0    0]\n",
      " ...\n",
      " [   2    4  118 ...    0    0    0]\n",
      " [   2  256  194 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f5264722760>\n",
      "(156348, 15)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):        \n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=7000,  # 7000단어를 기억할 수 있는 tokenizer 생성 \n",
    "        filters=' ',  # 문장 정제를 완료했기에 필터 필요치 않음\n",
    "        oov_token=\"<unk>\"  # 7000단어에 포함되지 못한 단어는 '<unk>'로 바꿈\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 15로 제한했기에 시쿼스 길이가 15 보다 긴 입력 데이터는 없음\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줌\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f96b401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   49    4   94  300   60   52    9  946 6274    3    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[0]) # 잘 만들어졌는지 하나만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7518923",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = tensor[:, :-1] #마지막 토큰을 제외하고 학습 데이터(X)로 저장\n",
    "tgt_input = tensor[:, 1:] #시작 토큰을 제외하고 타겟 데이터(y)으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a5d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2, random_state=29)\n",
    "# sklearn 라이브러리를 활용하여 데이터를 train과 validation으로 나눠줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88281a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (125078, 14)\n",
      "Target Train: (125078, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c6869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 피팅하는 과정에서 데이터를 numpy array 그대로 넣어주지 않고 데이터셋 객체를 만들어줄것\n",
    "# tf.data.Dataset객체를 사용할 경우 데이터 입력 파이프라인을 통한 속도 개선 및 각종 편의 기능이 제공된다고 함\n",
    "\n",
    "BUFFER_SIZE = len(enc_train) # 전체 데이터수 보다 크거나 같은 값으로 설정해야 모두를 섞을 수 있음\n",
    "BATCH_SIZE = 256 # 배치 사이즈 설정\n",
    "# steps_per_epoch = len(enc_train) // BATCH_SIZE # 한 번의 epoch에 몇번의 스텝이 있는지 설정하는데 어디에 쓰이는지 모르겠음..(???)\n",
    "                                               # 제외하겠음\n",
    "\n",
    "# tokenizer에서 구축한 7000개 + 포함되지 않은 0:<pad> = 7001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듬\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# validation 데이터 또한 tf.data.Dataset객체로 만들어줌\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "dataset_val = dataset.shuffle(len(enc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022e9fc",
   "metadata": {},
   "source": [
    "## 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae29a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 만들어주는 클래스를 만듬\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 임베딩 레이어는 입력 텐서의 단어 사전 인덱스 값을 이에 해당하는 워드 벡터로 바꿔주는 역할\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        # 자연어 처리에서 거의 기본적으로 쓰이는 RNN구조인 LSTMM 레이어를 두 층 추가해줌\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256 # 임베딩 레이어에 들어가는 인자\n",
    "                     # 값이 클수록 단어의 추상적 의미를 잘 파악하지만 데이터가 충분하지 않으면 오히려 혼란의 야기함\n",
    "hidden_size = 1024 # 모델을 처리하는 일꾼의 수라고 이해하면 쉬움\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f746915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 7001), dtype=float32, numpy=\n",
       "array([[[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-1.64626530e-04,  5.19412570e-04, -4.55870235e-04, ...,\n",
       "          3.50399874e-04,  1.50611260e-04,  8.09396588e-05],\n",
       "        [-1.06139814e-04,  8.37758707e-04, -1.76696849e-05, ...,\n",
       "          3.54170159e-04,  4.37719864e-04,  2.02760086e-04],\n",
       "        ...,\n",
       "        [ 4.65008634e-04,  1.06632325e-03,  9.35234362e-04, ...,\n",
       "         -6.32841256e-04, -7.50105362e-04,  2.04317446e-04],\n",
       "        [ 3.50154267e-04,  1.56984001e-03,  1.27843372e-03, ...,\n",
       "         -1.02228578e-03, -1.18253485e-03,  1.19892553e-04],\n",
       "        [ 2.67095485e-04,  2.06813752e-03,  1.64669717e-03, ...,\n",
       "         -1.43345783e-03, -1.57369801e-03,  6.01385291e-05]],\n",
       "\n",
       "       [[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-1.85571960e-04,  8.10743601e-04, -3.34532815e-04, ...,\n",
       "          1.84806835e-04,  4.50888532e-04, -1.44160003e-04],\n",
       "        [-3.43234897e-05,  1.44938019e-03, -7.67837046e-04, ...,\n",
       "         -6.13155544e-06,  7.69975595e-04, -3.25948495e-04],\n",
       "        ...,\n",
       "        [ 6.94367103e-04,  2.90755206e-03,  2.38324003e-03, ...,\n",
       "         -1.93864654e-03, -1.83800666e-03, -7.17805291e-04],\n",
       "        [ 6.97148615e-04,  3.12998542e-03,  2.77252123e-03, ...,\n",
       "         -2.29097717e-03, -2.19396385e-03, -6.33600808e-04],\n",
       "        [ 7.15096947e-04,  3.32475570e-03,  3.09796259e-03, ...,\n",
       "         -2.62112776e-03, -2.47044419e-03, -5.29274461e-04]],\n",
       "\n",
       "       [[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-7.31304390e-05,  1.00789813e-03, -4.02093370e-04, ...,\n",
       "          3.39535938e-04,  3.09472904e-04, -1.70951840e-04],\n",
       "        [ 1.37202034e-04,  1.02900853e-03, -2.27836354e-04, ...,\n",
       "          2.09940816e-04,  5.25618903e-04, -2.18129935e-04],\n",
       "        ...,\n",
       "        [-5.96429512e-04, -7.48020655e-04,  6.40076105e-05, ...,\n",
       "         -6.71432645e-04,  2.81274464e-04,  3.38657934e-04],\n",
       "        [-5.81760134e-04, -2.78407708e-04,  4.10526933e-04, ...,\n",
       "         -8.44048511e-04, -3.60285776e-04,  4.49417654e-04],\n",
       "        [-5.27004304e-04,  2.58150016e-04,  8.34366889e-04, ...,\n",
       "         -1.07888354e-03, -9.37435485e-04,  5.38854278e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-1.20802331e-04,  6.83984661e-04, -7.55200046e-04, ...,\n",
       "          3.22848791e-04, -2.47474149e-04, -2.06984070e-04],\n",
       "        [ 6.16353063e-05,  1.07158022e-03, -9.73037852e-04, ...,\n",
       "          1.71022213e-04, -5.79200336e-04, -8.12223298e-04],\n",
       "        ...,\n",
       "        [-5.11882303e-04,  3.05808336e-03,  7.01685785e-04, ...,\n",
       "         -1.20709080e-03, -2.28742696e-03, -1.01155450e-03],\n",
       "        [-4.71198990e-04,  3.32626444e-03,  1.28341629e-03, ...,\n",
       "         -1.62982347e-03, -2.42031971e-03, -8.08613840e-04],\n",
       "        [-3.91289359e-04,  3.54119646e-03,  1.80454261e-03, ...,\n",
       "         -2.03976291e-03, -2.52994476e-03, -6.23394211e-04]],\n",
       "\n",
       "       [[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-5.55728220e-05,  6.31633564e-04, -8.90080628e-05, ...,\n",
       "          3.80779937e-04,  2.93811347e-04, -2.22990071e-04],\n",
       "        [ 6.56363336e-05,  4.57519025e-04,  3.62575200e-04, ...,\n",
       "          4.94344102e-04,  4.47449042e-04, -3.52181582e-04],\n",
       "        ...,\n",
       "        [ 7.81591225e-05,  1.76345266e-03,  9.74716269e-04, ...,\n",
       "         -1.54438638e-03, -4.79443115e-05,  1.70535441e-05],\n",
       "        [ 5.52300735e-05,  2.25948030e-03,  1.45096763e-03, ...,\n",
       "         -1.90370181e-03, -6.15542405e-04, -1.05090170e-04],\n",
       "        [ 8.02296927e-05,  2.69868388e-03,  1.91830250e-03, ...,\n",
       "         -2.26189103e-03, -1.11405563e-03, -1.94934662e-04]],\n",
       "\n",
       "       [[-1.95602930e-04,  3.38643120e-04, -2.79349741e-04, ...,\n",
       "          9.39859892e-05,  1.01447076e-04, -9.90875924e-05],\n",
       "        [-3.64863547e-04,  6.61193917e-04, -3.35914316e-04, ...,\n",
       "          3.02199391e-04,  7.84244548e-07, -3.33401724e-04],\n",
       "        [-4.25483682e-04,  7.57933303e-04, -3.26141744e-04, ...,\n",
       "          5.20003960e-04, -1.49386819e-04, -5.38132444e-04],\n",
       "        ...,\n",
       "        [-1.28513342e-03,  1.44311649e-04, -5.67256182e-04, ...,\n",
       "          3.28881986e-04, -1.57601957e-03, -1.77838810e-04],\n",
       "        [-1.32220518e-03, -5.07889272e-05, -8.51216377e-04, ...,\n",
       "          3.07385460e-04, -1.52334874e-03, -2.04736949e-04],\n",
       "        [-1.36549724e-03,  1.42646168e-04, -6.31871342e-04, ...,\n",
       "          1.52997673e-04, -1.72553759e-03, -1.95605942e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb96dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1792256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7176025   \n",
      "=================================================================\n",
      "Total params: 22,607,961\n",
      "Trainable params: 22,607,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8922e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available()) # gpu가 사용가능한 상황인지 확인\n",
    "tf.config.list_physical_devices('GPU') # 이렇게 바꿔서 쓰라고 추천함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc6cff2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 93s 182ms/step - loss: 3.3715 - val_loss: 3.0065\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.9119 - val_loss: 2.7915\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.7473 - val_loss: 2.6456\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.6201 - val_loss: 2.5254\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.5103 - val_loss: 2.4137\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.4107 - val_loss: 2.3162\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 2.3184 - val_loss: 2.2245\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 89s 182ms/step - loss: 2.2319 - val_loss: 2.1402\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 2.1491 - val_loss: 2.0554\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 2.0690 - val_loss: 1.9732\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam() # 옵티마이저는 Adam으로 설정\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer) # 모델 학습을 위한 값을 설정\n",
    "# 우선 10번의 epoch 후에 val_loss가 2.2 아래로 떨어지는지 확인\n",
    "history1 = model.fit(dataset,\n",
    "                    epochs=10,\n",
    "                   validation_data=dataset_val,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b02a47",
   "metadata": {},
   "source": [
    "* 10 epochs안에 val_loss가 2.2 밑으로 떨어지는 것을 확인 -> val_loss가 1.9732로 나옴\n",
    "* 더 높은 수준을 위해 예제에서처럼 20 epochs를 더 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c016762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "488/488 [==============================] - 90s 184ms/step - loss: 1.9900 - val_loss: 1.8954\n",
      "Epoch 2/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.9126 - val_loss: 1.8166\n",
      "Epoch 3/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.8363 - val_loss: 1.7409\n",
      "Epoch 4/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.7615 - val_loss: 1.6641\n",
      "Epoch 5/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.6884 - val_loss: 1.5924\n",
      "Epoch 6/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.6172 - val_loss: 1.5243\n",
      "Epoch 7/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.5493 - val_loss: 1.4569\n",
      "Epoch 8/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.4849 - val_loss: 1.3940\n",
      "Epoch 9/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.4245 - val_loss: 1.3377\n",
      "Epoch 10/20\n",
      "488/488 [==============================] - 90s 183ms/step - loss: 1.3676 - val_loss: 1.2845\n",
      "Epoch 11/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.3156 - val_loss: 1.2364\n",
      "Epoch 12/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.2673 - val_loss: 1.1925\n",
      "Epoch 13/20\n",
      "488/488 [==============================] - 90s 183ms/step - loss: 1.2235 - val_loss: 1.1518\n",
      "Epoch 14/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.1834 - val_loss: 1.1136\n",
      "Epoch 15/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.1472 - val_loss: 1.0831\n",
      "Epoch 16/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.1149 - val_loss: 1.0544\n",
      "Epoch 17/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.0860 - val_loss: 1.0287\n",
      "Epoch 18/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.0599 - val_loss: 1.0049\n",
      "Epoch 19/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.0369 - val_loss: 0.9847\n",
      "Epoch 20/20\n",
      "488/488 [==============================] - 89s 183ms/step - loss: 1.0167 - val_loss: 0.9682\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(dataset,\n",
    "                    epochs=20,\n",
    "                   validation_data=dataset_val,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f01b2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence를 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듬\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor)\n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06419e2",
   "metadata": {},
   "source": [
    "### 문장 만들어보기!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e29b4609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love ma little nasty girl <end> '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff194e2",
   "metadata": {},
   "source": [
    "#### 정상 작동 확인!!\n",
    "\"나의 작은 끔찍한 소녀를 사랑해\"  \n",
    "조금은 이상하지만 Lyric이라면 가능할법하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a9749",
   "metadata": {},
   "source": [
    "* 여러개의 문장을 만들어보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72212575",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = generate_text(model, tokenizer, init_sentence=\"<start> i m\", max_len=20)\n",
    "s2 = generate_text(model, tokenizer, init_sentence=\"<start> you are\", max_len=20)\n",
    "s3 = generate_text(model, tokenizer, init_sentence=\"<start> where is\", max_len=20)\n",
    "s4 = generate_text(model, tokenizer, init_sentence=\"<start> she s\", max_len=20)\n",
    "s5 = generate_text(model, tokenizer, init_sentence=\"<start> it is\", max_len=20)\n",
    "s6 = generate_text(model, tokenizer, init_sentence=\"<start> this is\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "feb2b331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i m gonna make it alright but not right now <end> \n",
      "<start> you are the one so i make sure i behave <end> \n",
      "<start> where is your heart , when i m not around <end> \n",
      "<start> she s got me runnin round and round <end> \n",
      "<start> it is a woken dream <end> \n",
      "<start> this is my legacy , legacy <end> \n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)\n",
    "print(s4)\n",
    "print(s5)\n",
    "print(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a76a2e",
   "metadata": {},
   "source": [
    ">i m gonna make it alright but not right now \n",
    "you are the one so i make sure i behave  \n",
    "where is your heart , when i m not around  \n",
    "she s got me runnin round and round  \n",
    "it is a woken dream  \n",
    "this is my legacy , legacy  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1b149",
   "metadata": {},
   "source": [
    "* 이상하지만 용납 가능하다.  \n",
    "이 정도면 시적이기도 하고..뭔가 반전이 있고 잘 이어지는 느낌이다.  \n",
    "이건 다 legacy...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41c7af",
   "metadata": {},
   "source": [
    "---\n",
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3236ac",
   "metadata": {},
   "source": [
    "(1) 텍스트 생성 모델은 처음으로 다루어 보았는데 모델 학습이 잘 되었다.  \n",
    "문장을 만들어보니 아주 말이 안되는 결과는 나오지 않았다.  \n",
    "그렇다고 아주 자연스러운 문장은 아니지만 조금 부정적인 뉘앙스가 더 많이 표현되는것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd92215",
   "metadata": {},
   "source": [
    "(2) 네트워크를 만들고 모델을 학습하기 전에 데이터를 전처리 하는 것이 상당히 중요하다는 것을 다시 한번 느낀다.  \n",
    "그리고 그 과정 또한 간단하지 않고, 생각해야할 요소들이 많다.  \n",
    "그럼에도 미리 해야할 것들을 적어놓고, 하나하나 작성을 해보는 방식으로 하니 큰 어려움은 없었다.  \n",
    "다만 아직도 인덱스 관련하여 그 값이 포함되는지, 혹은 포함되지 않는지가 직관적으로 떠오르지 않는다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b14f19",
   "metadata": {},
   "source": [
    "(3) lms 노드에서 말한대로 10 epochs가 지난 후에 val_loss가 대략 1.9 정도로 나오며 학습이 잘 되는 모습을 확인 할 수 있었다.  \n",
    "총 30번의 epoch가 돌고 난 후에는 최종적으로 val_loss가 대략 0.97 정도 나왔는데 나쁘지 않은 값인것 같고,  \n",
    "epoch 마다 계산된 val_loss를 봤을때 학습을 더 진행한다면 조금 더 낮아질 수도 있을 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09c37d",
   "metadata": {},
   "source": [
    "(4) 모델을 만들어주는 TextGenerator 클래스를 만드는 부분이 혼란스럽다.  \n",
    "처음 model은 해당 클래스의 인스턴스로 선언이 되면서 아직 모델이 되었고, call 함수가 호출되어 모델이 빌드된것 같은데...  \n",
    "call은 매직 메서드로 \\_\\_call\\_\\_ 이렇게 쓰여야 하는 것 아닌가..??  \n",
    "그리고 model(src_sample) 이렇게 입력 샘플을 넣어줘서 모델을 호출해주어야만 네트워크가 완전히 생성된다.  \n",
    "call이 매직 메서드로 쓰인것이 맞는지 더 알아보아야 할듯!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5124d5c",
   "metadata": {},
   "source": [
    "(5) 텍스트를 이용한 딥러닝은 아예 처음 접해보았다.  \n",
    "결과를 보니 생각보다 흥미롭게 다가오지만, 역시나 익숙하지 않아서인지 어렵게 느껴진다.\n",
    "어떤 분야를 선택하더라도 그 하나만 알고 나머지를 모르는 것은 매우 위험하기에,  \n",
    "앞으로 텍스트를 다루지 않더라도 이런 기본적인 내용은 필히 숙지하고 있어야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
