{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b6de7c",
   "metadata": {},
   "source": [
    "# 노드 따라하기!! (프로젝트는 아래쪽에!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aa42808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "sentences = ['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc26edf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "\n",
    "index_to_word[0] = '<PAD>'\n",
    "index_to_word[1] = '<BOS>'\n",
    "index_to_word[2] = '<UNK>'\n",
    "index_to_word[3] = 'i'\n",
    "index_to_word[4] = 'feel'\n",
    "index_to_word[5] = 'hungry'\n",
    "index_to_word[6] = 'eat'\n",
    "index_to_word[7] = 'lunch'\n",
    "index_to_word[8] = 'now'\n",
    "index_to_word[9] = 'happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44b6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcff8116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e73f5d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']] + [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3ece51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47c99acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8508e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3107aa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.04473978  0.033767    0.031716    0.0356977 ]\n",
      "  [ 0.04800184 -0.01293838  0.04369137  0.03882836]\n",
      "  [ 0.00045777  0.04117789 -0.02848302 -0.01127741]\n",
      "  [ 0.02161782 -0.02938337  0.04670374  0.03789597]\n",
      "  [ 0.04983613  0.00269065 -0.01978065  0.03196811]]\n",
      "\n",
      " [[-0.04473978  0.033767    0.031716    0.0356977 ]\n",
      "  [ 0.04800184 -0.01293838  0.04369137  0.03882836]\n",
      "  [-0.03751893 -0.0097582   0.03523333  0.04517848]\n",
      "  [-0.02500234 -0.00887238  0.02023629  0.04723766]\n",
      "  [ 0.04983613  0.00269065 -0.01978065  0.03196811]]\n",
      "\n",
      " [[-0.04473978  0.033767    0.031716    0.0356977 ]\n",
      "  [ 0.01397545 -0.01816612 -0.00253273  0.04015949]\n",
      "  [ 0.04800184 -0.01293838  0.04369137  0.03882836]\n",
      "  [ 0.00045777  0.04117789 -0.02848302 -0.01127741]\n",
      "  [ 0.0405844  -0.02010299  0.00163462  0.04791028]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "word_vector_dim = 4\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs, \n",
    "                                              value=word_to_index['<PAD>'],\n",
    "                                              padding='post',\n",
    "                                              maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c10c7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e65c60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d709be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "307ea00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bf2ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5c84b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c5f89ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e07667c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82c8ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec87835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c05dac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "def3542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25073e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 21s 47ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6932 - val_accuracy: 0.4959\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6930 - val_accuracy: 0.5014\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6923 - accuracy: 0.5060 - val_loss: 0.6923 - val_accuracy: 0.5021\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6888 - accuracy: 0.5184 - val_loss: 0.6890 - val_accuracy: 0.5118\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6819 - accuracy: 0.5445 - val_loss: 0.6879 - val_accuracy: 0.5119\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6807 - accuracy: 0.5286 - val_loss: 0.6870 - val_accuracy: 0.5112\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6771 - accuracy: 0.5329 - val_loss: 0.6874 - val_accuracy: 0.5106\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6740 - accuracy: 0.5355 - val_loss: 0.6870 - val_accuracy: 0.5119\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6717 - accuracy: 0.5382 - val_loss: 0.6902 - val_accuracy: 0.5125\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6694 - accuracy: 0.5417 - val_loss: 0.6891 - val_accuracy: 0.5158\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6669 - accuracy: 0.5458 - val_loss: 0.6949 - val_accuracy: 0.5226\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6648 - accuracy: 0.5912 - val_loss: 0.6182 - val_accuracy: 0.7074\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6223 - accuracy: 0.6651 - val_loss: 1.0094 - val_accuracy: 0.6540\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.9198 - accuracy: 0.6051 - val_loss: 0.7444 - val_accuracy: 0.6032\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6817 - accuracy: 0.6162 - val_loss: 0.6465 - val_accuracy: 0.6344\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6326 - accuracy: 0.6439 - val_loss: 0.6303 - val_accuracy: 0.6529\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6184 - accuracy: 0.6644 - val_loss: 0.6314 - val_accuracy: 0.6427\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6443 - accuracy: 0.6079 - val_loss: 0.6469 - val_accuracy: 0.6073\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6385 - accuracy: 0.6132 - val_loss: 0.6429 - val_accuracy: 0.6132\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6310 - accuracy: 0.6248 - val_loss: 0.6284 - val_accuracy: 0.6402\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7126a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.6305 - accuracy: 0.6355\n",
      "[0.6304698586463928, 0.6354799866676331]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "887eb600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5c9b5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4OklEQVR4nO3deXxU1d348c+XBGTfcWFJAAsoyh7Aigtqq6BWUFyg/KpUK4JbxarF0goPPvRpH3laX7Roi9a1KFoXiop1BXEvAREFwQKCBFFD2CUsCd/fH+cO3AwzySQzd2Yy832/Xvc1d85d5sxkcr9zzrnnHFFVjDHGmHB1Up0BY4wx6ckChDHGmIgsQBhjjInIAoQxxpiILEAYY4yJyAKEMcaYiCxAmKQQkZdF5KpE75tKIrJeRH4QwHlVRL7nrf9FRH4Ty741eJ3RIvJqTfNZyXkHi0hRos9rki831Rkw6UtEdvueNgT2AeXe8+tUdXas51LVoUHsm+lUdVwiziMiHYEvgLqqWuadezYQ89/QZB8LECYqVW0cWheR9cDPVPX18P1EJDd00THGZA6rYjLVFqpCEJFfisjXwMMi0kJEXhSRYhHZ5q239x2zUER+5q2PEZF3RGS6t+8XIjK0hvt2EpFFIrJLRF4XkZki8vco+Y4lj3eLyLve+V4Vkda+7T8RkQ0iUiIikyr5fAaKyNcikuNLu1hElnvrA0TkfRHZLiKbReTPIlIvyrkeEZH/9j2/3TvmKxG5OmzfC0TkIxHZKSIbRWSKb/Mi73G7iOwWke+HPlvf8aeKyGIR2eE9nhrrZ1MZETnRO367iKwQkYt8284XkZXeOTeJyG1eemvv77NdRLaKyNsiYterJLMP3NTUsUBLIB8Yi/suPew9zwNKgT9XcvxAYDXQGvhf4G8iIjXY9wng30ArYArwk0peM5Y8/hj4KXA0UA8IXbC6A/d752/rvV57IlDVD4HvgLPDzvuEt14OTPDez/eBc4DrK8k3Xh6GePn5IdAFCG//+A64EmgOXACMF5Hh3rYzvMfmqtpYVd8PO3dL4CVghvfe/gC8JCKtwt7DEZ9NFXmuC7wAvOoddxMwW0S6ebv8DVdd2QQ4GXjTS/8FUAS0AY4BfgXYuEBJZgHC1NRBYLKq7lPVUlUtUdVnVXWPqu4CpgFnVnL8BlV9QFXLgUeB43AXgpj3FZE8oD9wl6ruV9V3gHnRXjDGPD6sqp+rainwNNDbS78UeFFVF6nqPuA33mcQzZPAKAARaQKc76WhqktU9QNVLVPV9cBfI+Qjksu9/H2qqt/hAqL//S1U1U9U9aCqLvdeL5bzggso/1HVx718PQmsAn7k2yfaZ1OZU4DGwO+8v9GbwIt4nw1wAOguIk1VdZuqLvWlHwfkq+oBVX1bbeC4pLMAYWqqWFX3hp6ISEMR+atXBbMTV6XR3F/NEubr0Iqq7vFWG1dz37bAVl8awMZoGY4xj1/71vf48tTWf27vAl0S7bVwpYVLROQo4BJgqapu8PLR1as++drLx29xpYmqVMgDsCHs/Q0UkQVeFdoOYFyM5w2de0NY2gagne95tM+myjyrqj+Y+s87Ahc8N4jIWyLyfS/9HmAN8KqIrBORibG9DZNIFiBMTYX/mvsF0A0YqKpNOVylEa3aKBE2Ay1FpKEvrUMl+8eTx83+c3uv2Srazqq6EnchHErF6iVwVVWrgC5ePn5Vkzzgqsn8nsCVoDqoajPgL77zVvXr+ytc1ZtfHrAphnxVdd4OYe0Hh86rqotVdRiu+mkurmSCqu5S1V+oamfgIuBWETknzryYarIAYRKlCa5Of7tXnz056Bf0fpEXAlNEpJ736/NHlRwSTx6fAS4UkdO8BuWpVP3/8wTwc1wg+kdYPnYCu0XkBGB8jHl4GhgjIt29ABWe/ya4EtVeERmAC0whxbgqsc5Rzj0f6CoiPxaRXBG5AuiOqw6Kx4e40sYdIlJXRAbj/kZzvL/ZaBFppqoHcJ/JQQARuVBEvue1Ne3AtdtUVqVnAmABwiTKvUADYAvwAfCvJL3uaFxDbwnw38BTuP4akdxLDfOoqiuAG3AX/c3ANlwjamVCbQBvquoWX/ptuIv3LuABL8+x5OFl7z28iat+eTNsl+uBqSKyC7gL79e4d+weXJvLu96dQaeEnbsEuBBXyioB7gAuDMt3tanqflxAGIr73O8DrlTVVd4uPwHWe1Vt43B/T3CN8K8Du4H3gftUdUE8eTHVJ9buYzKJiDwFrFLVwEswxmQ6K0GYWk1E+ovI8SJSx7sNdBiuLtsYEyfrSW1qu2OB53ANxkXAeFX9KLVZMiYzWBWTMcaYiKyKyRhjTEQZU8XUunVr7dixY6qzYYwxtcqSJUu2qGqbSNsyJkB07NiRwsLCVGfDGGNqFREJ70F/iFUxGWOMicgChDHGmIgsQBhjjIkoY9ogjDHJd+DAAYqKiti7d2/VO5uUql+/Pu3bt6du3boxH2MBwhhTY0VFRTRp0oSOHTsSfb4nk2qqSklJCUVFRXTq1Cnm46yKyRhTY3v37qVVq1YWHNKciNCqVatql/QsQBhj4mLBoXaoyd/JAoQxWW7hQli5MtW5MOnIAoQxWe6nP4Xf/CbVuaiZkpISevfuTe/evTn22GNp167doef79++v9NjCwkJuvvnmKl/j1FNPTUheFy5cyIUXXpiQcyWLNVIbk+W++QbWr0/Oa82eDZMmwZdfQl4eTJsGo0dXfVw0rVq1YtmyZQBMmTKFxo0bc9tttx3aXlZWRm5u5MtcQUEBBQUFVb7Ge++9V/MM1nKBlSBE5CER+VZEPo2yXURkhoisEZHlItLXt+0qEfmPt1wVVB6NyXbffQelpbAh6mALiTN7Nowd615L1T2OHevSE2nMmDGMGzeOgQMHcscdd/Dvf/+b73//+/Tp04dTTz2V1atXAxV/0U+ZMoWrr76awYMH07lzZ2bMmHHofI0bNz60/+DBg7n00ks54YQTGD16NKHRsOfPn88JJ5xAv379uPnmm6ssKWzdupXhw4fTs2dPTjnlFJYvXw7AW2+9dagE1KdPH3bt2sXmzZs544wz6N27NyeffDJvv/12Yj+wSgRZgngE+DPwWJTtQ3HTCnYBBuImch/omyu4ADfR+hIRmaeq2wLMqzFZqbjYPZaUuGDRqFFwrzVpEuzZUzFtzx6XHk8pIpKioiLee+89cnJy2LlzJ2+//Ta5ubm8/vrr/OpXv+LZZ5894phVq1axYMECdu3aRbdu3Rg/fvwRfQY++ugjVqxYQdu2bRk0aBDvvvsuBQUFXHfddSxatIhOnToxatSoKvM3efJk+vTpw9y5c3nzzTe58sorWbZsGdOnT2fmzJkMGjSI3bt3U79+fWbNmsV5553HpEmTKC8vZ0/4hxigwEoQqroI2FrJLsOAx9T5AGguIscB5wGvqepWLyi8BgwJKp/GZLMtvhmnv/wy2NeKdv4gXveyyy4jJycHgB07dnDZZZdx8sknM2HCBFasWBHxmAsuuICjjjqK1q1bc/TRR/PNN98csc+AAQNo3749derUoXfv3qxfv55Vq1bRuXPnQ/0LYgkQ77zzDj/5yU8AOPvssykpKWHnzp0MGjSIW2+9lRkzZrB9+3Zyc3Pp378/Dz/8MFOmTOGTTz6hSZMmNf1Yqi2VjdTtgI2+50VeWrT0I4jIWBEpFJHC4tBPIWNMzPz/NkEHiLy86qXHo5GvKPSb3/yGs846i08//ZQXXnghal+Ao4466tB6Tk4OZWVlNdonHhMnTuTBBx+ktLSUQYMGsWrVKs444wwWLVpEu3btGDNmDI89Fq1SJvFq9V1MqjpLVQtUtaBNm4jDmRtjKuEPEEG3Q0ybBg0bVkxr2NClB2nHjh20a+d+Yz7yyCMJP3+3bt1Yt24d672W/qeeeqrKY04//XRme40vCxcupHXr1jRt2pS1a9fSo0cPfvnLX9K/f39WrVrFhg0bOOaYY7j22mv52c9+xtKlSxP+HqJJZYDYBHTwPW/vpUVLN8YkWDIDxOjRMGsW5OeDiHucNSvx7Q/h7rjjDu6880769OmT8F/8AA0aNOC+++5jyJAh9OvXjyZNmtCsWbNKj5kyZQpLliyhZ8+eTJw4kUcffRSAe++9l5NPPpmePXtSt25dhg4dysKFC+nVqxd9+vThqaee4uc//3nC30M0gc5JLSIdgRdV9eQI2y4AbgTOxzVSz1DVAV4j9RIgdFfTUqCfqlbWnkFBQYHahEHGVM+dd8L06dCuHZx+Ojz+ePWO/+yzzzjxxBODyVwtsnv3bho3boyqcsMNN9ClSxcmTJiQ6mwdIdLfS0SWqGrE+30Du4tJRJ4EBgOtRaQId2dSXQBV/QswHxcc1gB7gJ9627aKyN3AYu9UU6sKDsaYmikuhtatoWPH5NzqmqkeeOABHn30Ufbv30+fPn247rrrUp2lhAgsQKhqpU356oouN0TZ9hDwUBD5MsYcVlwMbdq4huK33kp1bmqvCRMmpGWJIV61upHaGBOfUIDIz4dNmyCAKnpTi1mAMCaLbdlyuARRXg5ffZXqHJl0YgHCmCwWaoPIz3fPrR3C+FmAMCZLHTgA27cfrmKC4DvLmdrFAoQxWSo0zEabNtDB63lU20oQZ511Fq+88kqFtHvvvZfx48dHPWbw4MGEbok///zz2b59+xH7TJkyhenTp1f62nPnzmWlbyKNu+66i9dff70auY8snYYFtwBhTJbyB4iGDd1jbStBjBo1ijlz5lRImzNnTkzjIYEbhbV58+Y1eu3wADF16lR+8IMf1Ohc6coChDFZKtSLunVr95iXV/tKEJdeeikvvfTSocmB1q9fz1dffcXpp5/O+PHjKSgo4KSTTmLy5MkRj+/YsSNbvEg5bdo0unbtymmnnXZoSHBwfRz69+9Pr169GDFiBHv27OG9995j3rx53H777fTu3Zu1a9cyZswYnnnmGQDeeOMN+vTpQ48ePbj66qvZt2/fodebPHkyffv2pUePHqxatarS95fqYcFtwiBjslQoQISGMcvPh88+q/n5brkFvLl7EqZ3b7j33ujbW7ZsyYABA3j55ZcZNmwYc+bM4fLLL0dEmDZtGi1btqS8vJxzzjmH5cuX07Nnz4jnWbJkCXPmzGHZsmWUlZXRt29f+vXrB8All1zCtddeC8Cvf/1r/va3v3HTTTdx0UUXceGFF3LppZdWONfevXsZM2YMb7zxBl27duXKK6/k/vvv55ZbbgGgdevWLF26lPvuu4/p06fz4IMPRn1/qR4W3EoQxmSpSAHiyy/dZD61ib+ayV+99PTTT9O3b1/69OnDihUrKlQHhXv77be5+OKLadiwIU2bNuWiiy46tO3TTz/l9NNPp0ePHsyePTvqcOEhq1evplOnTnTt2hWAq666ikWLFh3afskllwDQr1+/QwP8RZPqYcGtBGFMlgq1QbRq5R7z8tykQVu3Hk6rjsp+6Qdp2LBhTJgwgaVLl7Jnzx769evHF198wfTp01m8eDEtWrRgzJgxUYf5rsqYMWOYO3cuvXr14pFHHmHhwoVx5Tc0ZHg8w4VPnDiRCy64gPnz5zNo0CBeeeWVQ8OCv/TSS4wZM4Zbb72VK6+8Mq68WgnCmCxVXAwtWkBoyuba2heicePGnHXWWVx99dWHSg87d+6kUaNGNGvWjG+++YaXX3650nOcccYZzJ07l9LSUnbt2sULL7xwaNuuXbs47rjjOHDgwKEhugGaNGnCrl27jjhXt27dWL9+PWvWrAHg8ccf58wzz6zRe0v1sOBWgjAmS4WG2Qjx94Xo2zfyMelq1KhRXHzxxYeqmkLDY59wwgl06NCBQYMGVXp83759ueKKK+jVqxdHH300/fv3P7Tt7rvvZuDAgbRp04aBAwceCgojR47k2muvZcaMGYcapwHq16/Pww8/zGWXXUZZWRn9+/dn3LhxNXpfobmye/bsScOGDSsMC75gwQLq1KnDSSedxNChQ5kzZw733HMPdevWpXHjxgmZWCjQ4b6TyYb7NqZ6zjrLdZZ75x33PDTsxr33QqxTDthw37VLdYf7tiomY7JUKCCEtGrl+kPUtr4QJjgWIIzJUqFxmEJEamdfCBMcCxDGZKGDB48sQYBrh6hugMiUaupMV5O/U6ABQkSGiMhqEVkjIhMjbM8XkTdEZLmILBSR9r5t5SKyzFvmBZlPY7LNjh1ueO9IAaI6VUz169enpKTEgkSaU1VKSkqoX79+tY4LcsrRHGAm8EOgCFgsIvNU1d9bZTrwmKo+KiJnA/8D/MTbVqqqvYPKnzHZLLyTXEheHnz7LZSWQoMGVZ+nffv2FBUVURw6oUlb9evXp3379lXv6BPkba4DgDWqug5AROYAwwB/gOgO3OqtLwDmBpgfY4wnfBymEP+trt26VX2eunXr0qlTp8RmzqSNIKuY2gEbfc+LvDS/j4FLvPWLgSYiEurDWV9ECkXkAxEZHukFRGSst0+h/YIxJnbRShA2L4TxS3Uj9W3AmSLyEXAmsAko97ble/fm/hi4V0SODz9YVWepaoGqFrQJ/6YbY6LyD/Xtl5fnHu1OJgPBVjFtAjr4nrf30g5R1a/wShAi0hgYoarbvW2bvMd1IrIQ6AOsDTC/xmSNaFVM7dpBnTpWgjBOkCWIxUAXEekkIvWAkUCFu5FEpLWIhPJwJ/CQl95CRI4K7QMMomLbhTEmDsXFrlNcw4YV03NzXZCwEoSBAAOEqpYBNwKvAJ8BT6vqChGZKiKhsXQHA6tF5HPgGGCal34iUCgiH+Mar38XdveTMSYO4eMw+dWkL4TJTIEO1qeq84H5YWl3+dafAZ6JcNx7QI8g82ZMNovUSS4kPx/eey+5+THpKdWN1MaYFKisBJGXBxs3uo50JrtZgDAmC4WPw+SXnw9lZbB5c3LzZNKPBQhjslBVbRBgdzIZCxDGZJ09e9xQGpVVMYE1VBsLEMZknWi9qENCAcJKEMYChDFZJlonuZDGjaFlSytBGAsQxmSdqkoQYH0hjGMBwpgsE20cJr9Y54WYPRs6dnTDc3Ts6J6bzGEBwpgsE0sJIjT1aGXzAM2eDWPHHt5vwwb33IJE5rAAYUyWKS52Yy41axZ9n/x82LULtm+Pvs+kSe6OKL89e1y6yQwWIIzJMqFOciLR94nlTqZo2+zup8xhAcKYLFPZOEwhoc5ylTVUh4JIrOmm9rEAYUyWqawXdUgsvamnTTtyuPCGDV26yQwWIIzJMpWNwxTSpg3Ur195CWL0aJg1ywUTEfc4a5ZLN5kh0OG+jTHpJ5YShMjhO5kqM3q0BYRMZiUIY7LIgQPuzqRYpnCPtS+EyVyBBggRGSIiq0VkjYhMjLA9X0TeEJHlIrJQRNr7tl0lIv/xlquCzKcx2aKkxD3GEiBiKUGYzBZYgBCRHGAmMBToDowSke5hu00HHlPVnsBU4H+8Y1sCk4GBwABgsoi0CCqvxmSLqsZh8svPh6+/hr17g82TSV9BliAGAGtUdZ2q7gfmAMPC9ukOvOmtL/BtPw94TVW3quo24DVgSIB5NSYrxNKLOiR0u2pRUXD5MektyADRDtjoe17kpfl9DFzirV8MNBGRVjEea4yppljGYQqJpS+EyWypbqS+DThTRD4CzgQ2ATHPhCsiY0WkUEQKi0M/jYwxUVWnBGEBwgQZIDYBHXzP23tph6jqV6p6iar2ASZ5adtjOdbbd5aqFqhqQZtYvvHGZLlQgGjZsup927Vzt7vanUzZK8gAsRjoIiKdRKQeMBKY599BRFqLSCgPdwIPeeuvAOeKSAuvcfpcL80YE4fiYmjRAurWrXrfevWgbVsrQWSzwAKEqpYBN+Iu7J8BT6vqChGZKiIXebsNBlaLyOfAMcA079itwN24ILMYmOqlGWPiEMs4TH7WFyK7BdqTWlXnA/PD0u7yrT8DPBPl2Ic4XKIwxiRALL2o/fLyYPHi4PJj0luqG6mNMUkUyzhMfvn5sHEjHDwYXJ5M+rIAYUwWqUkJYv9++Oab4PJk0pcFCGOyhGrN2iDAGqqzlQUIY7LE9u1QXm4BwsTOAoQxWaI64zCFxDL1qMlcFiCMyRLVGWYjpGlTaN7cShDZygKEMVmiOsNs+FlfiOxlAcKYLFHTAGHzQmQvCxDGZImatEGAK0FYgMhOFiCMyRJbtkDDhm6pjrw82LHDLSa7WIAwJktUt5NcSOhWV2uHyD4WIIzJEvEGCKtmyj4WIIzJEtUdhynE+kJkLwsQxmSJ6g6zEXLMMW5uCCtBZB8LEMZkiZpWMdWpAx06WAkiG1mAMCYL7NnjlprOzGu3umYnCxDGZIGa9oEIsQCRnQINECIyRERWi8gaEZkYYXueiCwQkY9EZLmInO+ldxSRUhFZ5i1/CTKfxmS6mozD5JeXB5s3u7khTPYIbMpREckBZgI/BIqAxSIyT1VX+nb7NW6u6vtFpDtuetKO3ra1qto7qPwZk01qOsxGSH6+m0+iqAg6d05cvkx6C7IEMQBYo6rrVHU/MAcYFraPAk299WbAVwHmx5islYgAAVbNlG2CDBDtgI2+50Vemt8U4P+JSBGu9HCTb1snr+rpLRE5PdILiMhYESkUkcLi0H+AMeYI8bZBWF+I7JTqRupRwCOq2h44H3hcROoAm4E8Ve0D3Ao8ISJNww9W1VmqWqCqBW1q+tPImCywZQvk5rq5HWqiQwf3aCWI7BJkgNgEdPA9b++l+V0DPA2gqu8D9YHWqrpPVUu89CXAWqBrgHk1JqOFelGL1Oz4o46CY4+1EkS2CTJALAa6iEgnEakHjATmhe3zJXAOgIiciAsQxSLSxmvkRkQ6A12AdQHm1ZiMVtNOcn52q2v2CSxAqGoZcCPwCvAZ7m6lFSIyVUQu8nb7BXCtiHwMPAmMUVUFzgCWi8gy4BlgnKpuDSqvxmS6mo7D5GcBIvsEdpsrgKrOxzU++9Pu8q2vBAZFOO5Z4Nkg82ZMNtmyBXr3ju8ceXnwz3+6211rWlVlapdUN1IbY5IgUVVM+/bBt98mJk8m/VmAMCbDHTgA27YlJkCAVTNlEwsQxmS4khL3GG8bhPWFyD4WIIzJcPGOwxRiJYjsE1OAEJFGXgc2RKSriFwkInWDzZoxJhHiHWYjpFkzaNLEShDZJNYSxCKgvoi0A14FfgI8ElSmjDGJk6gAIWK3umabWAOEqOoe4BLgPlW9DDgpuGwZYxIl3nGY/CxAZJeYA4SIfB8YDbzkpeUEkyVjTCKF2iBatYr/XHl5VsWUTWINELcAdwLPe72hOwMLAsuVMSZhiouhRQuom4BWw/x82LoVdu+O/1wm/cXUk1pV3wLeAvAaq7eo6s1BZswYkxiJ6CQX4r+T6SSrZM54sd7F9ISINBWRRsCnwEoRuT3YrBljEiER4zCFWF+I7BJrFVN3Vd0JDAdeBjrh7mQyxqS5LVuCKUGYzBdrgKjr9XsYDsxT1QO46UKNMWkukVVMxx7rJh6yAJEdYg0QfwXWA42ARSKSD+wMKlPGmMRQTWwJIifHzS5nVUzZIdZG6hnADF/SBhE5K5gsGWMSZccOKCtLXBsEWF+IbBJrI3UzEfmDiBR6y//hShPGmDSWqF7UftYXInvEWsX0ELALuNxbdgIPV3WQiAwRkdUiskZEJkbYniciC0TkIxFZLiLn+7bd6R23WkTOizGfxhifIAJEfj5s2uSGETeZLdYZ5Y5X1RG+5//lTQcalTen9Ezgh0ARsFhE5nmzyIX8GjcV6f0i0h03+1xHb30kbjiPtsDrItJVVctjzK8xhuBKEAcPuiDRsWPizmvST6wliFIROS30REQGAaVVHDMAWKOq61R1PzAHGBa2jwJNvfVmwFfe+jBgjqruU9UvgDXe+Ywx1RAaZiPRbRBg1UzZINYSxDjgMRFp5j3fBlxVxTHtgI2+50XAwLB9pgCvishNuDaNH/iO/SDs2HbhLyAiY4GxAHmhHjzGmEOCqmICa6jOBjGVIFT1Y1XtBfQEeqpqH+DsBLz+KOARVW0PnA88Hpp3IsZ8zVLVAlUtaJPI/wBjMkRxMTRs6JZE6dDBPVqAyHzVmlFOVXd6PaoBbq1i901AB9/z9l6a3zXA09653wfqA61jPNYYU4VEdpILadAAjj7aqpiyQTxTjkoV2xcDXUSkk4jUwzU6zwvb50vgHAAROREXIIq9/UaKyFEi0gnoAvw7jrwak5W2bEls+0OI9YXIDrG2QURS6VAbqlomIjcCr+DmjnjIGyp8KlCoqvOAXwAPiMgE73xjVFWBFSLyNLASKANusDuYjKm+IEoQ4O5kWrEi8ec16aXSACEiu4gcCARoUNXJVXU+7tZVf9pdvvWVwKAox04DplX1GsaY6IqL4cQTE3/e/HyYP98N5SFV1SWYWqvSAKGqTZKVEWNM4gVZgigtTew4Tyb9xNMGYYxJY3v2uCWoNgiwhupMZwHCmAwV6iQXxC986wuRHSxAGJOhgugkFxLql2oBIrNZgDAmQwUZIFq2hEaNrIop01mAMCZDBTEOU4iI9YXIBhYgjMlQQZYgwOaFyAYWIIzJUMXFbv7o5s2DOb+VIDKfBQhjMlRxsateCqojW16eq8b67rtgzm9SzwKEMRkqqHGYQkK3um7cWPl+pvayAGFMhgqqF3WI9YXIfBYgjMlQQQcI6wuR+SxAGJOhgg4QbdtCTo7dyZTJLEAYk4HKymDbtmDbIHJzoX17K0FkMgsQxmSgkhL3GPRIq9YXIrNZgDAmAwXdSS7E+kJktkADhIgMEZHVIrJGRCZG2P5HEVnmLZ+LyHbftnLftvCpSo0xlUhWgMjLg6IiV6VlMk88U45WSkRygJnAD4EiYLGIzPNmkQNAVSf49r8J6OM7Ramq9g4qf8ZksiDHYfLLz4fycti8GTp0CPa1TPIFWYIYAKxR1XWquh+YAwyrZP9RwJMB5seYrJHMKiawaqZMFWSAaAf4+1gWeWlHEJF8oBPwpi+5vogUisgHIjI8ynFjvX0Ki0P/EcaYQwGiVatgX8f6QmS2dGmkHgk8o6rlvrR8VS0AfgzcKyLHhx+kqrNUtUBVC9rYxLjGHFJc7Abpq1s32NcJBQi7kykzBRkgNgH+Wsn2XlokIwmrXlLVTd7jOmAhFdsnjDGV2LIl+OolcJMGtWplJYhMFWSAWAx0EZFOIlIPFwSOuBtJRE4AWgDv+9JaiMhR3nprYBCwMvxYY0xkQfei9jv5ZHj//ar3M7VPYAFCVcuAG4FXgM+Ap1V1hYhMFZGLfLuOBOaoqvrSTgQKReRjYAHwO//dT8aYyiUzQAwfDsuXw5o1yXk9kzxS8bpcexUUFGhhYWGqs2FMWjjuOLjgAnjwweBf68sv3d1Mv/sd/PKXwb+eSSwRWeK19x4hXRqpjTEJopq8NghwDdX9+8Ozzybn9UzyWIAwJsPs2OF6Nifzxr5LLoHFi+1upkxjAcKYDJOsTnJ+I0a4x+eeS95rmuBZgDAmwyRrmA2/Ll2gRw+rZso0FiCMyTCpKEGAK0W8+y58/XVyX9cExwKEMRkmlQFCFZ5/Prmva4JjAcKYDJOqAHHSSdC1q1UzZRILEMZkmC1boEEDaNgwua8r4koRCxcentHO1G4WIIzJMMnsRR1uxAg3P8Q8m+IrI1iAMCbDpDJA9O0LHTtaNVOmsABhTIZJZYAQcZ3mXnsNdu5MTR5M4liAMCbDbNmS3D4Q4UaMgP374cUXU5cHkxgWIIzJMKksQQCccoobLNCqmWo/CxDGZJDSUvjuu9QGiDp14OKL4eWXXV5M7WUBwpgMkqo+EOFGjHDB6l//Sm0+THwsQBiTQVIxDlMkZ5zhpiK1aqbaLdAAISJDRGS1iKwRkYkRtv9RRJZ5y+cist237SoR+Y+3XBVkPo3JFOlSgsjNdTPNvfgi7NuX2ryYmgssQIhIDjATGAp0B0aJSHf/Pqo6QVV7q2pv4E/Ac96xLYHJwEBgADBZRFoElVdjMkW6BAhw1Uy7drlbXk3tFGQJYgCwRlXXqep+YA4wrJL9RwFPeuvnAa+p6lZV3Qa8BgwJMK/GZIR0ChDnnAPNmlk1U20WZIBoB2z0PS/y0o4gIvlAJ+DN6h5rjDlsyxbIyXEX5lSrVw9+9CP45z/hwIFU58bURLo0Uo8EnlHV8uocJCJjRaRQRAqLQz+dqmn2bDc0QJ067nH27Np1vDF+xcWugbpOmvxnjxgB27bBW2+lOiemJoL8Gm0COviet/fSIhnJ4eqlmI9V1VmqWqCqBW1qUKaePRvGjoUNG9w49hs2uOexXqRTfbypvcrKYMUKeOIJ+NWv4IMPEnPeVHeSC3feedCokVUz1VaiqsGcWCQX+Bw4B3dxXwz8WFVXhO13AvAvoJN6mfEaqZcAfb3dlgL9VHVrtNcrKCjQwsLCauWxY0d3UQ5Xvz4MHux+hfkXkYrPX3gB9uw58vimTeGGG6BuXVfMjrTUrQs333y4ztgvPx/Wr4/tPcyeDZMmucni8/Jg2jQYPboaH4IJ3LZt8PHHFZcVKyre3dO7Nyxd6r5j8TjtNPf9evPNqvdNlssvh0WLYNMmV/1l0ouILFHVgkjbcoN6UVUtE5EbgVeAHOAhVV0hIlOBQlUNDQg8EpijvkilqltF5G5cUAGYWllwqKkvv4ycvnevG89eFQ4erLj40yIFB3CDlE2fXvN61w0bYNAgaNsW2rU7cmnb1o31HyqBhPIRKoGABYlYqMKOHbB5s/t7Nmjgfhw0aOCWo46q3gX74EFYs+bIYLDR15p29NHQqxfcdJN77NXLVb/cdBN8+KEbpiIeW7ZAz57xnSPRRoyAf/wD3nsPTj891bkx1RFYCSLZElmCiPUXfFXHq7qqhP37Ky4HDrjHs892F6dwjRrBwIHuF9emTbB795H7NG/uhjGIFISaN4cpUw5f8EIXvcoe69d3F8RM+IWn6m6v3LwZvvqq4hKeVlpa+bn8AaOy9Q0b4JNPDgfrnBw44YTDQSC0HHvska+xe7cL+sOHw2OPxffeW7WCkSNh5sz4zpNIu3a5aq9x4+Dee1OdGxMuJSWI2mDatIq/wMH9Mp82LTHHi7iqpLp13UU/3D33RD7+r3+tWALYufNwsAgtX30V/SKwfTvcckts7yFcbu7hYFHZY3gauIliysrco3+JlBaeXqeOu6jm5Lg8hK9XlbZtW8ULf6QxgBo1chfitm1hwIDD68cd586xd68LGKWl0df9z3ftclWEpaXuHNdeezgQdO/uPptYNG4MV10Fs2bBH/5Q817QZWWwdWt6tUEANGkC554Lzz0Hf/xj/NVoJnmyOkCELsI1rcNP1vFNm7rlxBMrpr/4YuQSTIcOsGxZxYvZ3r0V10OPb73lJpnfts3dGnnGGdCli9u2b1/Fx9B6ScnhtK1b3XLwoLvINm/u8hrpYu9fcnNd4Kxf3z0PlbbKy13pyh88QuuR0kLrzZu7i33fvnDhhYcv/KEg0Latu1Clq/Hj4c9/hocegjvuqNk5QtN8pluAAFfN9MILsHixC84h1oaW5lQ1I5Z+/fpptvn731UbNlR1l1e3NGzo0mvD8aaiM89U7dRJtby8Zsd/+qn7G8yZk9BsJcTWraq5uap33HE4zb4/6QHXJhzxupryC3uilmwMEKrunyk/X1XEPVbnnys/v+I/Z2jJz0/O8fHmP9M89ZT7/ObPr9nxCxa44994I6HZSphzz1U9/njVgwfd80R8f0z8KgsQadKdxtTU6NGuQfzgQfdYneJ5tLu4oqUn+njrB1LR8OGuEfu++2p2fDoNsxHJiBGwdi0sX+6ex/v9McGzAJHF8vKql57o4ydNOvJW4T17XHqsMqkner16rqH7pZdi7wfjl+4BYvhw93cKdZqL9/tjgmcBIotNm+bumvKr7l1c8RyfDiWQdAswY8e6vPz1r9U/NjQXRKtWic1Tohx9tOsHEQoQ8X5/TBJEq3uqbUu2tkHEK942gNrcBpKIRtIg2lAuvli1dWvVvXurd9yNN6o2bx7/6wdpxgz3OX/2mXtubVCphzVSm3QU7wVaJHKAEInt+HQNMK++6s5V3YvlFVeodulSvWOSrajIvbdp01KdExNSWYCwKiaTMqNHu85h+fmu81R+vnsea0N7vHXY8VZxxduGEq2K7OuvXV+U+++P7RyhKrJ//jO2102ldu3ccCI2eF/tYAHCpFQ8d2HFW4edrgHmN79xHefefdeN5RRNeIDZuxfWrUt9O0pVLrnEDUz4xRepzompigUIU2vFWwJJ5wAzZowb56myUkSkAFNeXr27wFJhxAj3+Nxzqc2HqZoFCFOrxVMCSecA06IFjBoFf/+7G3E2ktraj6BzZze8uVUzpT8LECarpXOAuf56N+jg449HPr429yMYMQLef98NPGnSlwUIY+IQZIDp1w/693c9qzXCqPyRAky9erWjH0Gomun551ObD1M5CxDGpFBVAeb66+Gzz9yMbJGODQWYkJ//vHaMhnriiW6xaqb0ZgHCmDR2xRWuPSLa+EyhABO6xfXyy5OWtbiNGOECX6Rpd016CDRAiMgQEVktImtEZGKUfS4XkZUiskJEnvCll4vIMm+ZF+lYYzJdgwZw9dXujp9Isw+GhIbZSNdxmCIZMcKVnObOTXVOTDSBBQgRyQFmAkOB7sAoEeketk8X4E5gkKqeBNzi21yqqr295aKg8mlMuhs3zk2K9OCD0fcJ/Qqv6Wx0qdCrl7ujyaqZ0leQJYgBwBpVXaeq+4E5wLCwfa4FZqrqNgBV/TbA/BhTK33ve3DeeW4Av7KyyPsUF7vSRqSpbdOViCtFvPGGmybXpJ8gA0Q7YKPveZGX5tcV6Coi74rIByIyxLetvogUeunDI72AiIz19ikstopMk8HGj3e3hL7wQuTtxcW1q3opZMQIF/Siva90N3u2Gz5ExD0++miqc5RYqZ6TOhfoAgwG2gOLRKSHqm4H8lV1k4h0Bt4UkU9Uda3/YFWdBcwCKCgoiHAjoDGZ4YIL3Fzj998PF1985PYtW2pngOjf3/XbuO02N7f5dde5ecprg2nTYPJk13sd4KuvXA/4W2+F7t3dGFnhS4cO7lbk2iLIALEJ6OB73t5L8ysCPlTVA8AXIvI5LmAsVtVNAKq6TkQWAn2AtRiThXJz3cXz17+Gzz+Hrl0rbi8url3tDyF16rhG6ltvhVtugXvucUOFXHNN+l5I//1vuPtuePHFyNv37YOcHHj7bXjiCdcQHxIqaeTnVwwcp57qgkq6CbKKaTHQRUQ6iUg9YCQQfjfSXFzpARFpjatyWiciLUTkKF/6IGBlgHk1Ju1dcw3UrQt/+cuR22prFRNAnz6wYAG8+aa7WF5/vRvN9sEH4cCBVOfusHfecW1BAwfCe+9F32/PHli40N1+vHevG5RwwQJ4+GG46y445xwX8N95B377WzeL4EknuU6PkyZF7hSZMtHGAU/EApwPfI775T/JS5sKXOStC/AH3MX/E2Ckl36q9/xj7/Gaql7L5oMw2WDkSDcp0HffVUxv1Eh1woTU5CmRDh5U/de/VPv3d/NGHH+86qOPqpaVpS4/b7yhOniwy0+bNqq//73qzp2JmU+kQYMjj+/cWfUf/0jee8YmDDImMyxa5P5r//a3w2l79ri03/42dflKtIMHVefNU+3d2723bt1Un3xStbw8ea//8suqp57qXv+441T/+MeKgTneCaOiBZjc3MPB8b773N83SJUFCOtJbUwtctpprjpi5szDVRGhTnK1sQ0iGhH40Y9gyRLXT6JuXTe6bc+e7nmoXj/Rc4qrwrx5rhpp6FDYuNF91uvWuTYS/9hX8Q7WGG3U3bIy9x5btXLVbfn5MHUqlJQcuW/gc6pHixy1bbEShMkWM2e6X5gffuieL1ninj//fEqzFajycleC6NbNvdfevVVvvfXIKprqTvnqP/8//qHaq5cequZ54AHVffsS/lYOqaqK6uBB1bfeUr3wwsPv7aabVNetc9sTMeWtauUlCNHQz5BarqCgQAsLC1OdDWMCt3OnuxPm0ktdw+crr8CQIa7Rc9CgVOcuWGVl8OST8F//BWuj3NPYvr0bSry01DUSl5ZWvv7dd/DUU7Bypbs7bNIk+PGPXUNykEIzAvonfWrYMHIpZOVKmD7dzQ9SXu7G3Fq40E1PGy4/3zWQx0pElqhqQcSN0SJHbVusBGGyyfjxqvXrq27Z4n4xgurq1anOVfLs3x/513dNl5NPdiWUZDeG//3vrsQg4h6r+vVfVKR6++2qTZtGfy8i1csDVoIwJrN88omrj58+3d1zP2GCq6Nu2TLVOUuejh3dfNzhWrSA3//eDT3SoIHreFfVem6ua0eoLXbscO8/0hAliSxBpLontTGmBnr0gNNPdz2rL7vMBYnmzat/ntmzXZXKl1+6Hs3TptWO+STA5TVSFc2f/lR73kNNNWsGf/6z60NRWno4vTpT3sbC7mIyppYaP97Vwz/9tLuDqU41/5tDdeAbNrjKiQ0b3POE3wkTkHjvIqrtRo+GBx4I9v1bFZMxtdS+fe5X/7ffwsknu2qn6ohWRVPdKorarDaXoBKlsiomK0EYU0sddRT87GduvSZ9IKLdhx8tPdPU9hJUMliAMKYWGzvWVS3VZBymvLzqpWeaSZMqtl+Aez5pUmryk44sQBhTi+Xnu0bZ8eOrf+y0aRV7BkPiGznTWbaXoGJhAcKYWu766+Gss6p/XLY38mZ7CSoWFiCMyWKjR7sG6YMH3WO2BAewElQsLEAYY7JStpegYmEd5YwxWWv0aAsIlbEShDHGmIgCDRAiMkREVovIGhGZGGWfy0VkpYisEJEnfOlXich/vOWqIPNpjDHmSIFVMYlIDjAT+CFQBCwWkXmqutK3TxfgTmCQqm4TkaO99JbAZKAAUGCJd+y2oPJrjDGmoiBLEAOANaq6TlX3A3OAYWH7XAvMDF34VfVbL/084DVV3eptew0YEmBejTHGhAkyQLQDNvqeF3lpfl2BriLyroh8ICJDqnEsIjJWRApFpLC4uDiBWTfGGJPqu5hygS7AYKA9sEhEesR6sKrOAmYBiEixiEQYeixttAa2pDoTlbD8xcfyFx/LX3ziyV9+tA1BBohNQAff8/Zeml8R8KGqHgC+EJHPcQFjEy5o+I9dWNmLqWoNRqNJHhEpjDZiYjqw/MXH8hcfy198gspfkFVMi4EuItJJROoBI4F5YfvMxQsEItIaV+W0DngFOFdEWohIC+BcL80YY0ySBFaCUNUyEbkRd2HPAR5S1RUiMhU3B+o8DgeClUA5cLuqlgCIyN24IAMwVVW3BpVXY4wxRwq0DUJV5wPzw9Lu8q0rcKu3hB/7EPBQkPlLslmpzkAVLH/xsfzFx/IXn0DylzEzyhljjEksG2rDGGNMRBYgjDHGRGQBIkFEpIOILPCNK/XzCPsMFpEdIrLMW+6KdK6A87leRD7xXr8wwnYRkRne+FnLRaRvEvPWzffZLBORnSJyS9g+Sf0MReQhEflWRD71pbUUkde8ccJe8+60i3Rs4OOJRcnfPSKyyvv7PS8izaMcW+l3IcD8TRGRTb6/4flRjq1yLLeA8veUL2/rRWRZlGOT8flFvK4k7TuoqrYkYAGOA/p6602Az4HuYfsMBl5McT7XA60r2X4+8DIgwCm4fiqpyGcO8DWQn8rPEDgD6At86kv7X2Citz4R+H2E41ribtluCbTw1lskKX/nArne+u8j5S+W70KA+ZsC3BbD338t0BmoB3wc/v8UVP7Ctv8fcFcKP7+I15VkfQetBJEgqrpZVZd667uAz4gwPEgtMAx4TJ0PgOYiclwK8nEOsFZVU9o7XlUXAeG3WA8DHvXWHwWGRzg0KeOJRcqfqr6qqmXe0w9wHU1TIsrnF4tYxnKLW2X5ExEBLgeeTPTrxqqS60pSvoMWIAIgIh2BPsCHETZ/X0Q+FpGXReSk5OYMcKPjvioiS0RkbITtMY2DlQQjif6PmerP8BhV3eytfw0cE2GfdPkcr8aVCCOp6rsQpBu9KrCHolSPpMPndzrwjar+J8r2pH5+YdeVpHwHLUAkmIg0Bp4FblHVnWGbl+KqTHoBf8L1JE+201S1LzAUuEFEzkhBHiolruf9RcA/ImxOh8/wEHVl+bS8V1xEJgFlwOwou6Tqu3A/cDzQG9iMq8ZJR6OovPSQtM+vsutKkN9BCxAJJCJ1cX/E2ar6XPh2Vd2pqru99flAXXFDjCSNqm7yHr8FnscV5f1iGUMraEOBpar6TfiGdPgMgW9C1W7e47cR9knp5ygiY4ALgdHeBeQIMXwXAqGq36hquaoeBB6I8rqp/vxygUuAp6Ltk6zPL8p1JSnfQQsQCeLVV/4N+ExV/xBln2O9/RCRAbjPvySJeWwkIk1C67jGzE/DdpsHXCnOKcAOX1E2WaL+ckv1Z+iZB4TuCLkK+GeEfVI2npi4YfPvAC5S1T1R9onluxBU/vxtWhdHed1YxnIL0g+AVapaFGljsj6/Sq4ryfkOBtkCn00LcBqumLccWOYt5wPjgHHePjcCK3B3ZHwAnJrkPHb2XvtjLx+TvHR/HgU3E+Ba4BOgIMl5bIS74DfzpaXsM8QFqs3AAVwd7jVAK+AN4D/A60BLb98C4EHfsVcDa7zlp0nM3xpc3XPoe/gXb9+2wPzKvgtJyt/j3ndrOe5Cd1x4/rzn5+Pu2lmbzPx56Y+EvnO+fVPx+UW7riTlO2hDbRhjjInIqpiMMcZEZAHCGGNMRBYgjDHGRGQBwhhjTEQWIIwxxkRkAcKYKohIuVQcZTZhI4uKSEf/SKLGpJNApxw1JkOUqmrvVGfCmGSzEoQxNeTNB/C/3pwA/xaR73npHUXkTW8wujdEJM9LP0bc/Awfe8up3qlyROQBb7z/V0Wkgbf/zd48AMtFZE6K3qbJYhYgjKlag7Aqpit823aoag/gz8C9XtqfgEdVtSduoLwZXvoM4C11Aw32xfXABegCzFTVk4DtwAgvfSLQxzvPuGDemjHRWU9qY6ogIrtVtXGE9PXA2aq6zhtQ7WtVbSUiW3DDRxzw0jeramsRKQbaq+o+3zk64sbs7+I9/yVQV1X/W0T+BezGjVg7V71BCo1JFitBGBMfjbJeHft86+Ucbhu8ADcuVl9gsTfCqDFJYwHCmPhc4Xt831t/Dzf6KMBo4G1v/Q1gPICI5IhIs2gnFZE6QAdVXQD8EmgGHFGKMSZI9ovEmKo1kIoT1/9LVUO3urYQkeW4UsAoL+0m4GERuR0oBn7qpf8cmCUi1+BKCuNxI4lGkgP83QsiAsxQ1e0Jej/GxMTaIIypIa8NokBVt6Q6L8YEwaqYjDHGRGQlCGOMMRFZCcIYY0xEFiCMMcZEZAHCGGNMRBYgjDHGRGQBwhhjTET/H/HhXn2basllAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a25881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7096992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.21.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     |████████████████████████████████| 23.4 MB 5.5 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=24328218 sha256=f05bf77a8e75ff01fc13428838a4fb02f8e927dcf5e14affcc8879ddfefd2bca\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed gensim-3.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 제대로 된 동작을 위해 버젼을 다운그레이드\n",
    "!pip install gensim\n",
    "\n",
    "!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3345760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a491ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53f05b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03432446,  0.04224148, -0.002476  ,  0.084374  , -0.05866981,\n",
       "        0.00873459,  0.07701198,  0.04851301,  0.04174719,  0.01149173,\n",
       "        0.07911645,  0.07712336,  0.04568939,  0.04858962, -0.07104567,\n",
       "       -0.03551871], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ddf7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('county', 0.8777061700820923),\n",
       " ('featuring', 0.8740423917770386),\n",
       " ('torment', 0.8698670864105225),\n",
       " ('condemned', 0.8678135871887207),\n",
       " ('mandy', 0.865607738494873),\n",
       " ('affairs', 0.8629537224769592),\n",
       " ('geeky', 0.8611271977424622),\n",
       " ('often', 0.8494324684143066),\n",
       " ('essential', 0.8424042463302612),\n",
       " ('charge', 0.8341334462165833)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23c09bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6eb0053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907792091369629),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.6618633270263672),\n",
       " ('passion', 0.6100709438323975),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536839962005615),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82a40b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab528687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f783e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 16s 90ms/step - loss: 0.6922 - accuracy: 0.5322 - val_loss: 0.6873 - val_accuracy: 0.5420\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6736 - accuracy: 0.5881 - val_loss: 0.6504 - val_accuracy: 0.6353\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.5888 - accuracy: 0.7169 - val_loss: 0.5278 - val_accuracy: 0.7416\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.4077 - accuracy: 0.8323 - val_loss: 0.3557 - val_accuracy: 0.8499\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.2895 - accuracy: 0.8813 - val_loss: 0.3301 - val_accuracy: 0.8591\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.2137 - accuracy: 0.9193 - val_loss: 0.3036 - val_accuracy: 0.8721\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.1615 - accuracy: 0.9434 - val_loss: 0.3085 - val_accuracy: 0.8731\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.1231 - accuracy: 0.9615 - val_loss: 0.3363 - val_accuracy: 0.8685\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0979 - accuracy: 0.9716 - val_loss: 0.3317 - val_accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0706 - accuracy: 0.9835 - val_loss: 0.3578 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0498 - accuracy: 0.9919 - val_loss: 0.3714 - val_accuracy: 0.8689\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0370 - accuracy: 0.9952 - val_loss: 0.3972 - val_accuracy: 0.8688\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0256 - accuracy: 0.9981 - val_loss: 0.4200 - val_accuracy: 0.8670\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0184 - accuracy: 0.9989 - val_loss: 0.4439 - val_accuracy: 0.8659\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 0.4594 - val_accuracy: 0.8661\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0104 - accuracy: 0.9996 - val_loss: 0.4804 - val_accuracy: 0.8648\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.4939 - val_accuracy: 0.8669\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.5091 - val_accuracy: 0.8647\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.5233 - val_accuracy: 0.8650\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.5349 - val_accuracy: 0.8657\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0328aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5798 - accuracy: 0.8537\n",
      "[0.5798423290252686, 0.8536800146102905]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7569f",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e58ff",
   "metadata": {},
   "source": [
    "# 프로젝트 : 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75b1a8",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "29e48562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1635e8a",
   "metadata": {},
   "source": [
    "## 2) 데이터로더 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "da573fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # [[YOUR CODE]]\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "        \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c069e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a982faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "더 빙 . . 진짜 짜증 나 네요 목소리\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(X_train[0], index_to_word))\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ecbb4",
   "metadata": {},
   "source": [
    "## 3) 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9e00b",
   "metadata": {},
   "source": [
    "* 데이터셋 내 문장 길이 분포\n",
    "* 적절한 최대 문장 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "be818d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  48\n",
      "전체 문장의 0.9548784420929768%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2.5*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2.5 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e0dc7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 48)\n",
      "(49157, 48)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # pre 성능이 좋다고 함\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # pre 성능이 좋다고 함\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2d00b7",
   "metadata": {},
   "source": [
    "## 4) 모델 구성 및 validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f79db69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21927.3\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train)*0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1eb35a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124182, 48)\n",
      "(124182,)\n"
     ]
    }
   ],
   "source": [
    "# 22000개를 validation set으로 지정\n",
    "X_val = X_train[:22000]\n",
    "y_val = y_train[:22000]\n",
    "\n",
    "partial_X_train = X_train[22000:]\n",
    "partial_y_train = y_train[22000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a8636",
   "metadata": {},
   "source": [
    "### RNN with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "672ed485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_56 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 128)               126720    \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,128,801\n",
      "Trainable params: 2,128,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000  # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 200  # 단어 하나를 표현하는 임베딩 벡터의 차원 \n",
    "\n",
    "model_0 = tf.keras.Sequential()\n",
    "model_0.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_0.add(tf.keras.layers.GRU(128))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "model_0.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model_0.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21dad6",
   "metadata": {},
   "source": [
    "### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "3d828399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_57 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, None, 16)          22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_1.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model_1.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model_1.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model_1.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_1.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df5a59",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling1D 이용한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5f7a9a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_58 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,001,617\n",
      "Trainable params: 2,001,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_2.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65078030",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce39718",
   "metadata": {},
   "source": [
    "### RNN with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d2fddb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 7s 11ms/step - loss: 0.1374 - accuracy: 0.9459 - val_loss: 0.4130 - val_accuracy: 0.8640\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.1019 - accuracy: 0.9611 - val_loss: 0.4919 - val_accuracy: 0.8592\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.0781 - accuracy: 0.9699 - val_loss: 0.6137 - val_accuracy: 0.8561\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.0619 - accuracy: 0.9762 - val_loss: 0.7365 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.0498 - accuracy: 0.9802 - val_loss: 0.8518 - val_accuracy: 0.8503\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.0408 - accuracy: 0.9837 - val_loss: 0.9489 - val_accuracy: 0.8490\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_0.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model_0.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a9cfa",
   "metadata": {},
   "source": [
    "### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a0a63c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 4s 6ms/step - loss: 0.4515 - accuracy: 0.7766 - val_loss: 0.3811 - val_accuracy: 0.8218\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 3s 5ms/step - loss: 0.3322 - accuracy: 0.8519 - val_loss: 0.3733 - val_accuracy: 0.8276\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 3s 5ms/step - loss: 0.2581 - accuracy: 0.8908 - val_loss: 0.3992 - val_accuracy: 0.8235\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.1811 - accuracy: 0.9264 - val_loss: 0.4612 - val_accuracy: 0.8166\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.1277 - accuracy: 0.9484 - val_loss: 0.5661 - val_accuracy: 0.8126\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.0965 - accuracy: 0.9600 - val_loss: 0.6504 - val_accuracy: 0.8085\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.0800 - accuracy: 0.9658 - val_loss: 0.7577 - val_accuracy: 0.8012\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_1 = model_1.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43a201",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling1D 이용한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4564bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.4236 - accuracy: 0.8096 - val_loss: 0.3366 - val_accuracy: 0.8522\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2992 - accuracy: 0.8745 - val_loss: 0.3342 - val_accuracy: 0.8557\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2500 - accuracy: 0.8994 - val_loss: 0.3443 - val_accuracy: 0.8565\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2035 - accuracy: 0.9221 - val_loss: 0.3660 - val_accuracy: 0.8536\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.1553 - accuracy: 0.9442 - val_loss: 0.4022 - val_accuracy: 0.8497\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 0.4538 - val_accuracy: 0.8470\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9784 - val_loss: 0.5151 - val_accuracy: 0.8447\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history_2 = model_2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55183dad",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f397b48c",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e716e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss, Accuracy 그래프 시각화\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('RNN Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('RNN Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3a7599c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.9371 - accuracy: 0.8477\n",
      "[0.9370606541633606, 0.8477124571800232]\n"
     ]
    }
   ],
   "source": [
    "# test 결과\n",
    "results = model_0.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274647c",
   "metadata": {},
   "source": [
    "처음엔 배치사이즈를 256으로 했었는데 validation 성능의 개선이 없어 배치사이즈를 32로 대폭 줄였다.  \n",
    "그럼에도 성능에서 큰 차이를 보이지 않고 3 epochs 이후부터는 오히려 성능이 하락하는 모습을 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484f47d",
   "metadata": {},
   "source": [
    "#### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "33e5761d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss, Accuracy 그래프 시각화\n",
    "\n",
    "history_dict_1 = history_1.history\n",
    "print(history_dict_1.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "acc = history_dict_1['accuracy']\n",
    "val_acc = history_dict_1['val_accuracy']\n",
    "loss = history_dict_1['loss']\n",
    "val_loss = history_dict_1['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('1-D CNN Traing and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('1-D Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cf663ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.7765 - accuracy: 0.8006\n",
      "[0.9370606541633606, 0.8477124571800232]\n"
     ]
    }
   ],
   "source": [
    "# test 결과\n",
    "results_1 = model_1.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f5fdb",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3bdb4587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loss, Accuracy 그래프 시각화\n",
    "\n",
    "history_dict_2 = history_2.history\n",
    "print(history_dict_2.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "acc = history_dict_2['accuracy']\n",
    "val_acc = history_dict_2['val_accuracy']\n",
    "loss = history_dict_2['loss']\n",
    "val_loss = history_dict_2['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('GMP1D CNN Traing and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('GMP1D Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "70f8b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.5202 - accuracy: 0.8414\n",
      "[0.9370606541633606, 0.8477124571800232]\n"
     ]
    }
   ],
   "source": [
    "# test 결과\n",
    "results_2 = model_2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92671f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd72d01",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ee1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제대로 된 동작을 위해 버젼을 다운그레이드\n",
    "# 위에서 수행해주었기에 건너뜀\n",
    "#!pip install gensim\n",
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7e5b1d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model_0.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6edbfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model_0.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0c520499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09303488  0.11226439 -0.14461125 -0.01034935  0.17099279  0.16874948\n",
      "  0.07331345  0.05238518 -0.1526046   0.05265008 -0.11662525 -0.04014652\n",
      "  0.17379928 -0.18306373  0.21060051  0.08134997 -0.09312661 -0.05729796\n",
      " -0.15048337 -0.05917407 -0.14463818 -0.11725764  0.17214611 -0.16570346\n",
      " -0.22153911 -0.08180784 -0.19435255  0.13462299  0.1323443   0.08340842\n",
      " -0.0956464   0.2896274  -0.05161378 -0.24549794  0.21973419  0.05814346\n",
      " -0.13509732  0.2947406  -0.00632603  0.19925994 -0.05230223 -0.09497326\n",
      " -0.16806538  0.19501805 -0.25471586 -0.02157324 -0.12078029  0.02421105\n",
      " -0.07810222 -0.14105077  0.02026598  0.08733696  0.1386075   0.03223716\n",
      " -0.16870937  0.14957407 -0.14688338 -0.0277502  -0.12144175 -0.12996809\n",
      " -0.25861993  0.1210236  -0.01873659 -0.12909257 -0.2597795  -0.12792194\n",
      " -0.05494439  0.12313418  0.25588626  0.14744562 -0.15495443  0.0146777\n",
      "  0.01767084 -0.15807788 -0.10619538  0.20337923  0.23458655  0.16803838\n",
      "  0.02549509 -0.10254306 -0.1564999   0.04348457 -0.04508828  0.11245143\n",
      "  0.3209937  -0.08494342 -0.11061087  0.23690742  0.07225656 -0.06352526\n",
      " -0.10299572 -0.075445    0.10017212  0.11159973 -0.17299333  0.01702276\n",
      "  0.25847438 -0.21842866 -0.06272872 -0.07763846  0.09464271 -0.01249746\n",
      "  0.08362812 -0.17450832  0.02807131 -0.17317902  0.21054277 -0.0712442\n",
      " -0.11219642  0.00496841 -0.02852739  0.2033347   0.20588122 -0.01093715\n",
      " -0.29533067 -0.23572966 -0.274447    0.02625871  0.03087997 -0.23243123\n",
      "  0.14835247  0.05772401  0.19515812  0.07476098  0.12062978  0.16408311\n",
      " -0.11834708  0.06863721  0.06422108 -0.11015471  0.26504314 -0.1615052\n",
      "  0.17737259 -0.36231163 -0.23758714  0.12316799  0.16085467  0.11926433\n",
      " -0.10597061 -0.0694413   0.07341047 -0.13177533 -0.07907648  0.12963316\n",
      "  0.02009585  0.20871237  0.0994029   0.10515219  0.06361619  0.14650218\n",
      "  0.10699039 -0.14390923  0.31240755 -0.0017836   0.05424421 -0.125742\n",
      "  0.14591026  0.05169673 -0.04966092  0.11602353  0.14185268 -0.0869572\n",
      " -0.06381738  0.21652143 -0.1113911   0.06544116 -0.02332912  0.06195961\n",
      " -0.06090749  0.22432229 -0.07162307 -0.02047314 -0.12620685  0.0690736\n",
      " -0.0846381  -0.13715532 -0.03484092  0.12335113  0.13981527 -0.2788117\n",
      " -0.18128128 -0.08448147  0.16008395  0.16509853  0.01223202 -0.16483124\n",
      " -0.15748833  0.0712768  -0.03796184 -0.09771938 -0.14646228  0.15059267\n",
      "  0.218081    0.10580274  0.06375192 -0.13555002 -0.06060168 -0.09509737\n",
      " -0.11758099 -0.12191508]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "print(word_vectors['사랑'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ac7cf296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('눈물', 0.8379384279251099),\n",
       " ('소장', 0.8142290115356445),\n",
       " ('재밌', 0.8055227994918823),\n",
       " ('토로', 0.8043040037155151),\n",
       " ('좋', 0.8008660078048706),\n",
       " ('밋', 0.7988518476486206),\n",
       " ('조기', 0.7987930774688721),\n",
       " ('명작', 0.7960962057113647),\n",
       " ('통일', 0.7936319708824158),\n",
       " ('묘', 0.7934836745262146)]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211990c",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad6935",
   "metadata": {},
   "source": [
    "https://github.com/Kyubyong/wordvectors 에서 한국어 Word2vec 자료 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "67b10cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3740246  -1.7353463   3.3915305  -2.569253   -1.4016607   1.4556127\n",
      "  0.9414557   1.9207907   0.16471806  0.4838317  -0.8547181   2.0879807\n",
      "  0.86741775  0.87539405 -0.09962013  0.22928311 -1.1858722   0.00858838\n",
      "  1.4999928  -0.16196461 -0.35184434 -0.92390764  1.0849575   0.3025011\n",
      "  2.7021565  -1.0263684   0.32864776 -0.76589465 -2.510981   -0.66225356\n",
      "  2.8434615   0.50130975 -1.021874   -1.4366034   1.1110784   0.5812605\n",
      " -0.5830406  -0.5785423   1.3634988   2.3074338  -1.4314893   0.45745876\n",
      "  1.1073523  -3.2135262  -0.2898375  -1.1622221   1.2369208  -0.7622987\n",
      " -0.37757635  1.1376442   0.01065568 -0.69105595  1.5159112   1.1534518\n",
      " -1.0119992  -0.5757404   1.1349088  -1.1289831   0.13004152  2.0451715\n",
      " -0.23940353  1.3604902   0.72700524  0.32545742  1.0612459   0.42252553\n",
      "  1.1442151   2.8774905   2.4377263  -1.340305    0.12629706 -0.07772489\n",
      " -0.59053177 -0.19007324  0.1396541  -1.8655105   0.9401054   0.5150856\n",
      "  0.7795373  -0.86505556  0.11842118 -1.8303713   1.337177   -1.0102932\n",
      " -0.37180334  0.00893255 -0.49141577 -1.05802    -2.5987291   0.9731856\n",
      "  0.34080654 -2.5973568   1.0046519  -1.3914212  -0.6504351  -0.9010805\n",
      " -1.1341541   0.75565654  1.2941337   0.0880572  -1.0341461  -0.1750075\n",
      " -0.01880708 -1.0835075  -2.0333962   1.1372623   1.0626172  -1.8369784\n",
      " -2.2662086  -3.382057    1.6751666  -0.2988223  -0.25563756 -1.5594274\n",
      "  0.6313433  -1.2667153  -1.6857744  -1.0949599   0.7742313  -0.6095523\n",
      "  3.19503     0.13200459  1.7937473  -2.8782516   1.3821276   2.2895143\n",
      "  0.0741943  -0.41046414  1.438796    0.19373988  1.4294034   1.5025262\n",
      "  1.4849502   1.5754777   2.7793512  -0.6885003  -0.30154693 -1.708323\n",
      "  1.1030879  -2.2597387   1.1909146   2.4399316   0.3990314   0.904154\n",
      "  0.5454401  -1.3235748  -0.64812386  0.22390233  0.9657619  -0.47360668\n",
      " -0.10278235 -1.0679734  -0.91414386  0.92069     0.3549338   0.32858834\n",
      "  0.84870636  3.596926   -1.6651102   0.23658653  1.0515738   0.40531915\n",
      " -0.773514   -0.93460965 -0.3946274  -1.5657727   1.183652    2.5277\n",
      "  0.57700926  1.7051374  -1.8249958  -2.0328498   0.6617798   0.85747904\n",
      "  0.31782728 -1.1660796   0.32923874  2.2055087  -0.12782003  2.0455444\n",
      " -0.1724252   0.46001154  1.559042   -1.6152996  -0.84242785  0.7553168\n",
      "  0.39734274  0.07714175  0.05610155  0.32837135  1.0220716   1.3816743\n",
      "  0.8049544   0.28728685 -0.97610044  0.8861181  -0.01250968 -1.4845604\n",
      " -1.5236791  -1.5451258 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3352817960.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector = word2vec['사랑']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/ko.bin'\n",
    "word2vec = Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['사랑']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f952488e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1098788216.py:2: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  word2vec.similar_by_word(\"사랑\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬픔', 0.7216662764549255),\n",
       " ('행복', 0.6759077310562134),\n",
       " ('절망', 0.6468985080718994),\n",
       " ('기쁨', 0.6458414196968079),\n",
       " ('이별', 0.6334798336029053),\n",
       " ('추억', 0.6320937275886536),\n",
       " ('인생', 0.6216273307800293),\n",
       " ('애정', 0.6206069588661194),\n",
       " ('연인', 0.6186063289642334),\n",
       " ('유혹', 0.5965287685394287)]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5d3b79f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1730871920.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word[i] in word2vec:\n",
      "/tmp/ipykernel_13/1730871920.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix[i] = word2vec[index_to_word[i]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92fa4a",
   "metadata": {},
   "source": [
    "#### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "00960027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_59 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 128)               126720    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,128,801\n",
      "Trainable params: 2,128,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN with GRU\n",
    "e_model_0 = tf.keras.Sequential()\n",
    "e_model_0.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_0.add(tf.keras.layers.GRU(128))           # RNN에서 가장 많이 쓰는 LSTM 모델의 개선버젼\n",
    "e_model_0.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_0.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "1c6de4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_60 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 42, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 2, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN\n",
    "e_model_1 = tf.keras.Sequential()\n",
    "e_model_1.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim,\n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning))\n",
    "e_model_1.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "e_model_1.add(tf.keras.layers.MaxPooling1D(5))\n",
    "e_model_1.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "e_model_1.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "e_model_1.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "e_model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "e_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "efd5ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_63 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,001,617\n",
      "Trainable params: 2,001,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "e_model_2 = tf.keras.Sequential()\n",
    "e_model_2.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, \n",
    "                                      embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                      input_length=maxlen, \n",
    "                                      trainable=True))   # trainable을 True로 주면 Fine-tuning))\n",
    "e_model_2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "e_model_2.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "e_model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "e_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea455961",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b7ed5e1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 6s 9ms/step - loss: 0.4224 - accuracy: 0.8011 - val_loss: 0.3344 - val_accuracy: 0.8506\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.3065 - accuracy: 0.8686 - val_loss: 0.3209 - val_accuracy: 0.8582\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.2663 - accuracy: 0.8894 - val_loss: 0.3201 - val_accuracy: 0.8614\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.2348 - accuracy: 0.9047 - val_loss: 0.3114 - val_accuracy: 0.8707\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.2062 - accuracy: 0.9170 - val_loss: 0.3274 - val_accuracy: 0.8678\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.1747 - accuracy: 0.9312 - val_loss: 0.3567 - val_accuracy: 0.8667\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.1460 - accuracy: 0.9428 - val_loss: 0.4112 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.1185 - accuracy: 0.9551 - val_loss: 0.4461 - val_accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 4s 8ms/step - loss: 0.0960 - accuracy: 0.9637 - val_loss: 0.4922 - val_accuracy: 0.8548\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# RNN with GRU\n",
    "e_model_0.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history = e_model_0.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "90964301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4906 - accuracy: 0.8525\n",
      "[0.4906134605407715, 0.8525133728981018]\n"
     ]
    }
   ],
   "source": [
    "e_results_0 = e_model_0.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5dc28142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.5413 - accuracy: 0.7164 - val_loss: 0.4543 - val_accuracy: 0.7830\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.4050 - accuracy: 0.8134 - val_loss: 0.4080 - val_accuracy: 0.8086\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.3532 - accuracy: 0.8415 - val_loss: 0.3974 - val_accuracy: 0.8160\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8581 - val_loss: 0.4053 - val_accuracy: 0.8140\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2953 - accuracy: 0.8724 - val_loss: 0.4131 - val_accuracy: 0.8137\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2709 - accuracy: 0.8837 - val_loss: 0.4254 - val_accuracy: 0.8117\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 3s 5ms/step - loss: 0.2462 - accuracy: 0.8967 - val_loss: 0.4494 - val_accuracy: 0.8095\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 3s 5ms/step - loss: 0.2214 - accuracy: 0.9085 - val_loss: 0.4667 - val_accuracy: 0.8099\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 1D CNN\n",
    "e_model_1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_1 = e_model_1.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "79df2406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4775 - accuracy: 0.8111\n",
      "[0.4775051474571228, 0.8111153841018677]\n"
     ]
    }
   ],
   "source": [
    "e_results_1 = e_model_1.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a5f8eaf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "486/486 [==============================] - 3s 4ms/step - loss: 0.6513 - accuracy: 0.6239 - val_loss: 0.5734 - val_accuracy: 0.7021\n",
      "Epoch 2/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.5242 - accuracy: 0.7382 - val_loss: 0.4889 - val_accuracy: 0.7625\n",
      "Epoch 3/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.4527 - accuracy: 0.7864 - val_loss: 0.4429 - val_accuracy: 0.7912\n",
      "Epoch 4/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.4087 - accuracy: 0.8134 - val_loss: 0.4210 - val_accuracy: 0.8049\n",
      "Epoch 5/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.3802 - accuracy: 0.8301 - val_loss: 0.4101 - val_accuracy: 0.8112\n",
      "Epoch 6/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.3576 - accuracy: 0.8427 - val_loss: 0.3968 - val_accuracy: 0.8194\n",
      "Epoch 7/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.3388 - accuracy: 0.8535 - val_loss: 0.3947 - val_accuracy: 0.8215\n",
      "Epoch 8/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.3220 - accuracy: 0.8620 - val_loss: 0.3932 - val_accuracy: 0.8246\n",
      "Epoch 9/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.3066 - accuracy: 0.8708 - val_loss: 0.3921 - val_accuracy: 0.8269\n",
      "Epoch 10/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2931 - accuracy: 0.8779 - val_loss: 0.3889 - val_accuracy: 0.8288\n",
      "Epoch 11/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2785 - accuracy: 0.8853 - val_loss: 0.3979 - val_accuracy: 0.8263\n",
      "Epoch 12/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.8909 - val_loss: 0.3993 - val_accuracy: 0.8283\n",
      "Epoch 13/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2528 - accuracy: 0.8979 - val_loss: 0.4102 - val_accuracy: 0.8270\n",
      "Epoch 14/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2400 - accuracy: 0.9045 - val_loss: 0.4052 - val_accuracy: 0.8300\n",
      "Epoch 15/20\n",
      "486/486 [==============================] - 2s 4ms/step - loss: 0.2282 - accuracy: 0.9092 - val_loss: 0.4102 - val_accuracy: 0.8295\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "e_model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_2 = e_model_2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "12cba73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.4194 - accuracy: 0.8284\n",
      "[0.4194493889808655, 0.8284069299697876]\n"
     ]
    }
   ],
   "source": [
    "e_results_2 = e_model_2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880adc45",
   "metadata": {},
   "source": [
    "### 여러 방식으로 도전!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e143929d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_64 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,170,529\n",
      "Trainable params: 2,170,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM\n",
    "e_model_t = tf.keras.Sequential()\n",
    "e_model_t.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t.add(tf.keras.layers.LSTM(128))           # RNN에서 가장 많이 쓰는 LSTM 모델의 개선버젼\n",
    "e_model_t.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "33fbaa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "486/486 [==============================] - 6s 10ms/step - loss: 0.4180 - accuracy: 0.8039 - val_loss: 0.3392 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 5s 9ms/step - loss: 0.3073 - accuracy: 0.8686 - val_loss: 0.3240 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.2664 - accuracy: 0.8889 - val_loss: 0.3187 - val_accuracy: 0.8648\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.2330 - accuracy: 0.9048 - val_loss: 0.3139 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.2046 - accuracy: 0.9180 - val_loss: 0.3334 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.1720 - accuracy: 0.9321 - val_loss: 0.3585 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.1424 - accuracy: 0.9450 - val_loss: 0.3868 - val_accuracy: 0.8654\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.1131 - accuracy: 0.9567 - val_loss: 0.4778 - val_accuracy: 0.8589\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 5s 10ms/step - loss: 0.0906 - accuracy: 0.9657 - val_loss: 0.5133 - val_accuracy: 0.8593\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM\n",
    "e_model_t.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t = e_model_t.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ff78f0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.5245 - accuracy: 0.8560\n",
      "[0.5244756937026978, 0.8559716939926147]\n"
     ]
    }
   ],
   "source": [
    "e_results_t = e_model_t.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9387c8e",
   "metadata": {},
   "source": [
    "* LSTM의 optimizer를 RMSprop으로 설정하면 어떤 결과를 가져올지???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "60326915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_65 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,170,529\n",
      "Trainable params: 2,170,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 7s 12ms/step - loss: 0.4404 - accuracy: 0.7898 - val_loss: 0.3589 - val_accuracy: 0.8395\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.3262 - accuracy: 0.8582 - val_loss: 0.3331 - val_accuracy: 0.8533\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.2856 - accuracy: 0.8782 - val_loss: 0.3340 - val_accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.2563 - accuracy: 0.8926 - val_loss: 0.3216 - val_accuracy: 0.8601\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.2292 - accuracy: 0.9061 - val_loss: 0.3608 - val_accuracy: 0.8471\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.2028 - accuracy: 0.9182 - val_loss: 0.3455 - val_accuracy: 0.8587\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.1767 - accuracy: 0.9303 - val_loss: 0.3638 - val_accuracy: 0.8583\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.1519 - accuracy: 0.9400 - val_loss: 0.3940 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 4s 9ms/step - loss: 0.1278 - accuracy: 0.9509 - val_loss: 0.4141 - val_accuracy: 0.8620\n",
      "Epoch 00009: early stopping\n",
      "1537/1537 - 3s - loss: 0.4214 - accuracy: 0.8587\n",
      "[0.4213657081127167, 0.8586569428443909]\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(128))           # RNN에서 가장 많이 쓰는 LSTM 모델의 개선버젼\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='RMSprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342c893",
   "metadata": {},
   "source": [
    "GRU와 SimpleRNN을 조합하면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "394202bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_75 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 48, 256)           351744    \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,403,105\n",
      "Trainable params: 2,403,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 28s 55ms/step - loss: 0.4563 - accuracy: 0.7799 - val_loss: 0.3675 - val_accuracy: 0.8389\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 26s 53ms/step - loss: 0.3276 - accuracy: 0.8581 - val_loss: 0.4287 - val_accuracy: 0.8297\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 26s 53ms/step - loss: 0.2803 - accuracy: 0.8823 - val_loss: 0.3169 - val_accuracy: 0.8687\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 26s 53ms/step - loss: 0.2432 - accuracy: 0.8997 - val_loss: 0.3229 - val_accuracy: 0.8669\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 25s 52ms/step - loss: 0.2070 - accuracy: 0.9158 - val_loss: 0.3176 - val_accuracy: 0.8705\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 25s 52ms/step - loss: 0.1683 - accuracy: 0.9337 - val_loss: 0.4084 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 25s 52ms/step - loss: 0.1331 - accuracy: 0.9480 - val_loss: 0.3943 - val_accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 25s 52ms/step - loss: 0.1009 - accuracy: 0.9616 - val_loss: 0.4747 - val_accuracy: 0.8680\n",
      "Epoch 00008: early stopping\n",
      "1537/1537 - 9s - loss: 0.4978 - accuracy: 0.8606\n",
      "[0.4978441894054413, 0.8606098890304565]\n"
     ]
    }
   ],
   "source": [
    "#GRU + SimpleRNN\n",
    "e_model_t3 = tf.keras.Sequential()\n",
    "e_model_t3.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t3.add(tf.keras.layers.GRU(256, return_sequences=True))           # RNN에서 가장 많이 쓰는 LSTM 모델의 개선버젼\n",
    "e_model_t3.add(tf.keras.layers.SimpleRNN(128))\n",
    "e_model_t3.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t3.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t3.summary()\n",
    "\n",
    "e_model_t3.compile(optimizer='RMSprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t3 = e_model_t3.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t3 = e_model_t3.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "659a4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_67 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 48, 64)            51072     \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 64)                18816     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,070,945\n",
      "Trainable params: 2,070,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 10s 13ms/step - loss: 0.4464 - accuracy: 0.7856 - val_loss: 0.3608 - val_accuracy: 0.8387\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 6s 11ms/step - loss: 0.3282 - accuracy: 0.8572 - val_loss: 0.3213 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2901 - accuracy: 0.8774 - val_loss: 0.3089 - val_accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2655 - accuracy: 0.8883 - val_loss: 0.3147 - val_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 6s 11ms/step - loss: 0.2452 - accuracy: 0.8990 - val_loss: 0.3376 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2257 - accuracy: 0.9077 - val_loss: 0.3175 - val_accuracy: 0.8709\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2066 - accuracy: 0.9163 - val_loss: 0.3334 - val_accuracy: 0.8677\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.1881 - accuracy: 0.9249 - val_loss: 0.3515 - val_accuracy: 0.8626\n",
      "Epoch 00008: early stopping\n",
      "1537/1537 - 6s - loss: 0.3516 - accuracy: 0.8617\n",
      "[0.35157784819602966, 0.8617491126060486]\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional\n",
    "e_model_t3 = tf.keras.Sequential()\n",
    "e_model_t3.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t3.add(tf.keras.layers.GRU(64, return_sequences=True))           # RNN에서 가장 많이 쓰는 LSTM 모델의 개선버젼\n",
    "e_model_t3.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)))\n",
    "e_model_t3.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t3.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t3.summary()\n",
    "\n",
    "e_model_t3.compile(optimizer='RMSprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t3 = e_model_t3.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t3 = e_model_t3.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed67f0b",
   "metadata": {},
   "source": [
    "LSTM을 여러겹 쌓으면??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c731aabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_68 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 48, 32)            29824     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 48, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 48, 32)            8320      \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,055,329\n",
      "Trainable params: 2,055,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 11s 15ms/step - loss: 0.4469 - accuracy: 0.7820 - val_loss: 0.3437 - val_accuracy: 0.8495\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.3149 - accuracy: 0.8647 - val_loss: 0.3256 - val_accuracy: 0.8590\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.2797 - accuracy: 0.8826 - val_loss: 0.3126 - val_accuracy: 0.8672\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.2544 - accuracy: 0.8956 - val_loss: 0.3273 - val_accuracy: 0.8672\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.2296 - accuracy: 0.9072 - val_loss: 0.3368 - val_accuracy: 0.8629\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.2080 - accuracy: 0.9170 - val_loss: 0.3399 - val_accuracy: 0.8672\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.1855 - accuracy: 0.9279 - val_loss: 0.3707 - val_accuracy: 0.8633\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 6s 13ms/step - loss: 0.1640 - accuracy: 0.9378 - val_loss: 0.3881 - val_accuracy: 0.8601\n",
      "Epoch 00008: early stopping\n",
      "1537/1537 - 7s - loss: 0.3950 - accuracy: 0.8552\n",
      "[0.3949523866176605, 0.8551782965660095]\n"
     ]
    }
   ],
   "source": [
    "# RNN with Deep LSTM\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(32, return_sequences=True))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "e_model_t2.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "e_model_t2.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "e_model_t2.add(tf.keras.layers.LSTM(32, return_sequences=False))\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa19b16",
   "metadata": {},
   "source": [
    "LSTM의 필터수를 줄여보자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "07898d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_69 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 16)                13888     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,014,177\n",
      "Trainable params: 2,014,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 5s 7ms/step - loss: 0.4560 - accuracy: 0.7804 - val_loss: 0.3588 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.3309 - accuracy: 0.8588 - val_loss: 0.3334 - val_accuracy: 0.8560\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2962 - accuracy: 0.8757 - val_loss: 0.3328 - val_accuracy: 0.8578\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2721 - accuracy: 0.8873 - val_loss: 0.3306 - val_accuracy: 0.8593\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2538 - accuracy: 0.8971 - val_loss: 0.3371 - val_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2352 - accuracy: 0.9057 - val_loss: 0.3463 - val_accuracy: 0.8590\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2185 - accuracy: 0.9127 - val_loss: 0.3550 - val_accuracy: 0.8579\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2027 - accuracy: 0.9209 - val_loss: 0.3736 - val_accuracy: 0.8565\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.1866 - accuracy: 0.9276 - val_loss: 0.3849 - val_accuracy: 0.8560\n",
      "Epoch 00009: early stopping\n",
      "1537/1537 - 3s - loss: 0.3941 - accuracy: 0.8509\n",
      "[0.3941272497177124, 0.8509469628334045]\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM (필터수를 대폭 줄여서..)\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(16))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc2a6b",
   "metadata": {},
   "source": [
    "배치사이즈를 줄이면..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "994f0a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 49, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 16)                13888     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,014,177\n",
      "Trainable params: 2,014,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 5s 7ms/step - loss: 0.4666 - accuracy: 0.7716 - val_loss: 0.3640 - val_accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.3338 - accuracy: 0.8565 - val_loss: 0.3383 - val_accuracy: 0.8522\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2991 - accuracy: 0.8737 - val_loss: 0.3314 - val_accuracy: 0.8560\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2757 - accuracy: 0.8853 - val_loss: 0.3414 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2568 - accuracy: 0.8944 - val_loss: 0.3390 - val_accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2381 - accuracy: 0.9029 - val_loss: 0.3506 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2213 - accuracy: 0.9116 - val_loss: 0.3540 - val_accuracy: 0.8573\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 3s 6ms/step - loss: 0.2045 - accuracy: 0.9190 - val_loss: 0.3701 - val_accuracy: 0.8541\n",
      "Epoch 00008: early stopping\n",
      "1537/1537 - 3s - loss: 0.3764 - accuracy: 0.8514\n",
      "[0.3763841986656189, 0.8513741493225098]\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM (배치사이즈 높임)\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(16))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27274dd6",
   "metadata": {},
   "source": [
    "Bidirectional 레이어를 추가해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "eeb4aa83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_70 (Embedding)     (None, 48, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 48, 16)            13888     \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 32)                4224      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,018,657\n",
      "Trainable params: 2,018,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 50s 13ms/step - loss: 0.4403 - accuracy: 0.7905 - val_loss: 0.3495 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.3200 - accuracy: 0.8638 - val_loss: 0.3313 - val_accuracy: 0.8571\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2878 - accuracy: 0.8803 - val_loss: 0.3320 - val_accuracy: 0.8599\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2641 - accuracy: 0.8913 - val_loss: 0.3273 - val_accuracy: 0.8619\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2429 - accuracy: 0.9019 - val_loss: 0.3327 - val_accuracy: 0.8628\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2260 - accuracy: 0.9102 - val_loss: 0.3434 - val_accuracy: 0.8616\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.2074 - accuracy: 0.9192 - val_loss: 0.3624 - val_accuracy: 0.8560\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.1898 - accuracy: 0.9284 - val_loss: 0.3726 - val_accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "486/486 [==============================] - 5s 11ms/step - loss: 0.1735 - accuracy: 0.9349 - val_loss: 0.3880 - val_accuracy: 0.8535\n",
      "Epoch 00009: early stopping\n",
      "1537/1537 - 6s - loss: 0.3925 - accuracy: 0.8509\n",
      "[0.3925097584724426, 0.8508859276771545]\n"
     ]
    }
   ],
   "source": [
    "# RNN with Bidirectional layer\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(16, return_sequences=True))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "e_model_t2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=False)))\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f482b",
   "metadata": {},
   "source": [
    "왜...!!!! 성능에 큰 차이가 없는것인가..???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82327f",
   "metadata": {},
   "source": [
    "그렇다면 단어 수를 늘려보자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "be5eb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_(train_data, test_data, num_words=10000):\n",
    "    # [[YOUR CODE]]\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "8a6156ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  48\n",
      "전체 문장의 0.9548784420929768%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "X_train_, y_train_, X_test_, y_test_, word_to_index_ = load_data_(train_data, test_data, num_words=20000)\n",
    "index_to_word_ = {index:word for word, index in word_to_index_.items()}\n",
    "\n",
    "total_data_text = list(X_train_) + list(X_test_)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2.5*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2.5 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5518be54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2944812522.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word_[i] in word2vec_:\n",
      "/tmp/ipykernel_13/2944812522.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix_1[i] = word2vec_[index_to_word_[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 48)\n",
      "(49157, 48)\n",
      "(124255, 48)\n",
      "(124255,)\n"
     ]
    }
   ],
   "source": [
    "word2vec_ = Word2Vec.load(word2vec_path)\n",
    "vocab_size = 20000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수\n",
    "embedding_matrix_1 = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word_[i] in word2vec_:\n",
    "        embedding_matrix_1[i] = word2vec_[index_to_word_[i]]\n",
    "        \n",
    "X_train_ = tf.keras.preprocessing.sequence.pad_sequences(X_train_,\n",
    "                                                        value=word_to_index_[\"<PAD>\"],\n",
    "                                                        padding='pre', # pre 성능이 좋다고 함\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test_ = tf.keras.preprocessing.sequence.pad_sequences(X_test_,\n",
    "                                                       value=word_to_index_[\"<PAD>\"],\n",
    "                                                       padding='pre', # pre 성능이 좋다고 함\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train_.shape)\n",
    "print(X_test_.shape)\n",
    "\n",
    "X_val_ = X_train_[:int(len(X_train_)*0.15)]\n",
    "y_val_ = y_train_[:int(len(X_train_)*0.15)]\n",
    "\n",
    "partial_X_train_ = X_train_[int(len(X_train_)*0.15):]\n",
    "partial_y_train_ = y_train_[int(len(X_train_)*0.15):]\n",
    "\n",
    "print(partial_X_train_.shape)\n",
    "print(partial_y_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c3debe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_72 (Embedding)     (None, 48, 200)           4000000   \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 16)                13888     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,014,177\n",
      "Trainable params: 4,014,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "486/486 [==============================] - 6s 8ms/step - loss: 0.5029 - accuracy: 0.7562 - val_loss: 0.3624 - val_accuracy: 0.8439\n",
      "Epoch 2/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.3576 - accuracy: 0.8551 - val_loss: 0.3406 - val_accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.3139 - accuracy: 0.8764 - val_loss: 0.3322 - val_accuracy: 0.8607\n",
      "Epoch 4/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.2839 - accuracy: 0.8905 - val_loss: 0.3489 - val_accuracy: 0.8583\n",
      "Epoch 5/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.2574 - accuracy: 0.9014 - val_loss: 0.3598 - val_accuracy: 0.8568\n",
      "Epoch 6/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.2368 - accuracy: 0.9103 - val_loss: 0.3626 - val_accuracy: 0.8568\n",
      "Epoch 7/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.4020 - val_accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "486/486 [==============================] - 3s 7ms/step - loss: 0.1958 - accuracy: 0.9268 - val_loss: 0.4138 - val_accuracy: 0.8538\n",
      "Epoch 00008: early stopping\n",
      "1537/1537 - 3s - loss: 0.4117 - accuracy: 0.8519\n",
      "[0.41167977452278137, 0.8519437909126282]\n"
     ]
    }
   ],
   "source": [
    "# RNN with LSTM (배치사이즈 높임)\n",
    "word_vector_dim = 200\n",
    "\n",
    "e_model_t2 = tf.keras.Sequential()\n",
    "e_model_t2.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                        word_vector_dim, \n",
    "                                        embeddings_initializer=Constant(embedding_matrix_1),  # 카피한 임베딩을 여기서 활용\n",
    "                                        input_length=maxlen, \n",
    "                                        trainable=True))   # trainable을 True로 주면 Fine-tuning)\n",
    "e_model_t2.add(tf.keras.layers.LSTM(16))           # RNN에서 가장 많이 쓰는 LSTM 모델\n",
    "e_model_t2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "e_model_t2.add(tf.keras.layers.Dropout(0.5))\n",
    "e_model_t2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1 dim \n",
    "\n",
    "e_model_t2.summary()\n",
    "\n",
    "# RNN\n",
    "e_model_t2.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "e_history_t2 = e_model_t2.fit(partial_X_train_,\n",
    "                    partial_y_train_,\n",
    "                    epochs=epochs,\n",
    "                    callbacks = early,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_, y_val_),\n",
    "                    verbose=1)\n",
    "\n",
    "e_results_t2 = e_model_t2.evaluate(X_test_, y_test_, verbose=2)\n",
    "\n",
    "print(e_results_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51110a",
   "metadata": {},
   "source": [
    "#### 평가 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb502bb",
   "metadata": {},
   "source": [
    "1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.  \n",
    "  -> 3가지 이상의 모델이 성공적으로 시도됨  \n",
    "2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.  \n",
    "  -> gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함  \n",
    "3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.  \n",
    "  -> 네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67a32d",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2178a2",
   "metadata": {},
   "source": [
    "1. GRU, 1-D CNN, GlobalMaxPooling1D 세 가지를 활용한 모델을 생성하여 학습하였고 결과도 보았다.  \n",
    "GRU를 사용했을 때의 test accuracy가 0.8477로 가장 높았다.  \n",
    "세 모델의 공통점으로 시각화 자료를 봤을 때, validation loss는 우상향하고, validation accuracy는 정체되는 것을 볼 수 있다.\n",
    "학습에 대한 loss과 accuracy는 각각 우하향, 우상향 하며 성능이 높아지는 것을 확인할 수 있으나,  \n",
    "validation 데이터에 대해서는 전혀 다른 양상을 보이는 이유를 모르겠다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751c2af",
   "metadata": {},
   "source": [
    "2. gensim의 버젼은 다운그레이드하고 해달 모델을 이용하여 임베딩 레이어를 분석하였다.  \n",
    "각 단어가 벡터 형태로 바뀐것을 확인할 수 있었는데, 그 예로 '사랑' 이라는 단어를 나타냈다.  \n",
    "'사랑' 이라는 단어와 유사한 값을 가지는 단어를 찾아보았을 때, 결과값들이 생각보다 큰 연관성이 있는것 같지는 않았다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39075",
   "metadata": {},
   "source": [
    "3. 한국어 Word2vec을 활용하여 GRU 모델에 적용했을때, accuracy가 0.8525로 약간의 향상이 있었다.  \n",
    "심지어 GlobalMaxPooling1D 모델에서는 accuracy가 낮아졌다.\n",
    "LSTM에 적용해보니 accuracy 값 자체가 가장 높은 값인 **0.8560**을 기록해 가장 학습이 잘 된것을 볼 수 있다.\n",
    "결론적으로 한국어 Word2vec이 유의미한 성능향상을 가져오지 않았다고 본다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce5f4a",
   "metadata": {},
   "source": [
    "4. 여러 방식으로 모델을 학습해보았다. 단순히 레이어를 쌓아보기도 하고, 레이어를 바꿔보기도 하고, 레이어를 조합해보기도 했다.  \n",
    "결론적으로는 accuracy 0.8617의 양방향 LSTM 방식이 가장 높은 성능을 나타냈다.  \n",
    "양방향 방식은, 문장에서 앞 단어에 따라 뒤의 단어를 예측할 수 있지만, 뒤 단어에 따라 앞 단어를 예측할 수도 있다는 전제하에 등장했다.  \n",
    "그래서 그런건지 조금은 성능이 앞서있는 것을 볼 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbed43",
   "metadata": {},
   "source": [
    "5. NLP를 또다시 접해보면서 조금은 NLP에 대한 관심이 늘었고 이해도도 높아진것 같다.  \n",
    "CV가 익숙해서 CV에 흥미가 높은건 아닌지 조금 더 생각해 볼 필요가 있다.  \n",
    "여전히 코드를 보며 따라하는 방식으로만 진행이 가능하고 제로베이스에서는 할 수 있는 것이 없다.  \n",
    "기본 코드에 대해서 연습을 해야겠다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
